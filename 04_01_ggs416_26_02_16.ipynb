{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDaZrya1KrWeYFHOefe4rb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edwardoughton/satellite-image-analysis/blob/main/04_01_ggs416_26_02_16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üõ∞Ô∏è GGS416 Satellite Image Analysis Week 4 üõ∞Ô∏è\n",
        "\n",
        "This week we will cover:\n",
        "\n",
        " * Classical image segmentation approaches\n"
      ],
      "metadata": {
        "id": "5CfXtnDONcAX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning objectives\n",
        "\n",
        "By the end of this week, students will be able to:\n",
        "\n",
        "* Explain practical foundations of classical image segmentation methods.\n",
        "* Implement histogram-based segmentation using Otsu and Multi-Otsu thresholding.\n",
        "* Apply clustering-based segmentation using K-means in RGB feature space.\n",
        "* Generate superpixels using SLIC and interpret compactness effects.\n",
        "* Perform marker-controlled watershed segmentation.\n",
        "* Apply graph-based segmentation using the Felzenszwalb algorithm.\n",
        "* Compare segmentation outputs across heterogeneous landscapes (urban, agricultural, forest, coastal).\n",
        "* Analyze the influence of algorithm parameters on segmentation results.\n",
        "* Critically evaluate strengths and weaknesses of classical segmentation approaches for satellite imagery.\n",
        "\n"
      ],
      "metadata": {
        "id": "p5oPUH_XPZHQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Microsoft Copilot Pro\n",
        "\n",
        "Please sign up:\n",
        "\n",
        "https://docs.github.com/en/copilot/how-tos/manage-your-account/get-free-access-to-copilot-pro"
      ],
      "metadata": {
        "id": "B5XqnyzFqD2l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visual Studio Code\n",
        "\n",
        "Please install before next week:\n",
        "\n",
        "https://code.visualstudio.com/"
      ],
      "metadata": {
        "id": "9k03B2NiqPRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AI advice\n",
        "\n",
        "* Make sure you are using the newest models, where possible.\n",
        "* Free apps will have more outdated models.\n",
        "* Do use your educational email for free access to certain products."
      ],
      "metadata": {
        "id": "P7OkuPkdsWKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Setup and location presets\n",
        "!pip -q install pystac-client planetary-computer odc-stac rasterio requests\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from rasterio.transform import from_origin\n",
        "from rasterio.crs import CRS\n",
        "\n",
        "import pystac_client\n",
        "import planetary_computer\n",
        "import odc.stac\n",
        "from pystac.extensions.eo import EOExtension as eo"
      ],
      "metadata": {
        "id": "dBEXkHp_qB0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Location presets and search STAC\n",
        "STAC_API_URL = \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n",
        "COLLECTION = \"landsat-c2-l2\"\n",
        "\n",
        "# 5 locations (min_lon, min_lat, max_lon, max_lat) in EPSG:4326\n",
        "LOCATION_PRESETS = {\n",
        "    \"ames_ia\": [-93.77, 41.88, -93.47, 42.18],\n",
        "    \"los_angeles_ca\": [-118.375, 33.90, -118.075, 34.20],\n",
        "    \"new_orleans_la\": [-90.25, 29.80, -89.95, 30.10],\n",
        "    \"phoenix_az\": [-112.25, 33.30, -111.95, 33.60],\n",
        "    \"mt_jefferson_or\": [-121.95, 44.50, -121.65, 44.80],\n",
        "}\n",
        "\n",
        "time_of_interest = \"2024-05-01/2024-09-30\"\n",
        "cloud_limit = 10  # percent\n",
        "\n",
        "DATA_DIR = Path(\"data_landsat\")\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "catalog = pystac_client.Client.open(\n",
        "    STAC_API_URL,\n",
        "    modifier=planetary_computer.sign_inplace\n",
        ")\n",
        "\n",
        "print(catalog)"
      ],
      "metadata": {
        "id": "5qBBp8JaRFzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Function to save RGB images as geotifs in a certain folder\n",
        "def save_rgb_geotiff(data, out_path):\n",
        "    \"\"\"\n",
        "    Save RGB (red/green/blue) from an odc-stac xarray dataset to a GeoTIFF.\n",
        "    This keeps georeferencing so rasterio cropping works.\n",
        "    \"\"\"\n",
        "    # Build (bands, rows, cols) array for rasterio\n",
        "    rgb = data[[\"red\", \"green\", \"blue\"]].to_array().values  # shape (3, y, x)\n",
        "\n",
        "    # Get georeferencing from odc-stac dataset\n",
        "    transform = data.odc.geobox.transform\n",
        "    crs = data.odc.geobox.crs\n",
        "\n",
        "    profile = {\n",
        "        \"driver\": \"GTiff\",\n",
        "        \"height\": rgb.shape[1],\n",
        "        \"width\": rgb.shape[2],\n",
        "        \"count\": 3,\n",
        "        \"dtype\": rgb.dtype,\n",
        "        \"crs\": crs,\n",
        "        \"transform\": transform,\n",
        "        \"tiled\": True,\n",
        "        \"blockxsize\": 256,\n",
        "        \"blockysize\": 256,\n",
        "    }\n",
        "\n",
        "    # Now write our image to the path we specify\n",
        "    with rasterio.open(out_path, \"w\", **profile) as dst:\n",
        "        dst.write(rgb)\n",
        "\n",
        "    return out_path\n"
      ],
      "metadata": {
        "id": "I4XQSoe2qb8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Downloading and cropping multiple images at once\n",
        "downloaded_rgb_tifs = []\n",
        "\n",
        "for location_name, bbox in LOCATION_PRESETS.items():\n",
        "\n",
        "    search = catalog.search(\n",
        "        collections=[COLLECTION],\n",
        "        bbox=bbox,\n",
        "        datetime=time_of_interest,\n",
        "        query={\"eo:cloud_cover\": {\"lt\": cloud_limit}},\n",
        "    )\n",
        "    items = search.item_collection()\n",
        "\n",
        "    # Lecture 2: choose lowest cloud cover\n",
        "    selected_item = min(items, key=lambda item: eo.ext(item).cloud_cover)\n",
        "\n",
        "    # Lecture 2: load bands with odc-stac\n",
        "    bands = [\"red\", \"green\", \"blue\"]\n",
        "    data = odc.stac.stac_load([selected_item], bands=bands, bbox=bbox).isel(time=0)\n",
        "\n",
        "    out_tif = DATA_DIR / f\"{location_name}_rgb.tif\"\n",
        "    save_rgb_geotiff(data, out_tif)\n",
        "\n",
        "    downloaded_rgb_tifs.append(out_tif)\n",
        "    print(\"Saved:\", out_tif)\n"
      ],
      "metadata": {
        "id": "piIMcE8Nqqqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Crop images (covered in Lecture 3)\n",
        "from rasterio.windows import from_bounds\n",
        "from rasterio.warp import transform_bounds\n",
        "\n",
        "CROPPED_DIR = DATA_DIR / \"cropped\" # Set our directory path\n",
        "CROPPED_DIR.mkdir(exist_ok=True)   # Create our directory\n",
        "\n",
        "def crop_geotiff_to_bbox(in_path, out_path, bbox_wgs84):\n",
        "    \"\"\"\n",
        "    Crop a GeoTIFF to a lon/lat bbox using the Lecture 3 approach.\n",
        "    \"\"\"\n",
        "    with rasterio.open(in_path) as src:\n",
        "        # 1) Convert bbox from EPSG:4326 to the raster CRS (UTM for Landsat)\n",
        "        minlon, minlat, maxlon, maxlat = bbox_wgs84\n",
        "        minx, miny, maxx, maxy = transform_bounds(\n",
        "            \"EPSG:4326\", src.crs, minlon, minlat, maxlon, maxlat, densify_pts=21\n",
        "        )\n",
        "\n",
        "        # 2) Lecture 3: build a raster window from bounds\n",
        "        win = from_bounds(minx, miny, maxx, maxy, src.transform)\n",
        "\n",
        "        # 3) Read just that window\n",
        "        data = src.read(window=win)\n",
        "\n",
        "        # 4) Update metadata and write output (Lecture 3)\n",
        "        prof = src.profile\n",
        "        prof.update(\n",
        "            height=data.shape[1],\n",
        "            width=data.shape[2],\n",
        "            transform=rasterio.windows.transform(win, src.transform),\n",
        "        )\n",
        "\n",
        "        with rasterio.open(out_path, \"w\", **prof) as dst:\n",
        "            dst.write(data)\n",
        "\n",
        "    return out_path\n",
        "\n",
        "# Now execute our cropping function, looping over our images\n",
        "cropped_tifs = []\n",
        "\n",
        "for tif_path in downloaded_rgb_tifs: # This is the path to our image\n",
        "\n",
        "    location_name = tif_path.stem.replace(\"_rgb\", \"\")\n",
        "    bbox = LOCATION_PRESETS[location_name]\n",
        "\n",
        "    out_path = CROPPED_DIR / f\"{location_name}_rgb_cropped.tif\"\n",
        "    crop_geotiff_to_bbox(tif_path, out_path, bbox)\n",
        "\n",
        "    cropped_tifs.append(out_path)\n",
        "    print(\"Cropped:\", out_path.name)\n"
      ],
      "metadata": {
        "id": "zyINwlflVXWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Plot images (from Lecture 1)\n",
        "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, ax in enumerate(axes):\n",
        "    if i < len(cropped_tifs):\n",
        "        path = cropped_tifs[i]\n",
        "        label = path.stem.replace(\"_rgb_cropped\", \"\").replace(\"_\", \" \").title()\n",
        "\n",
        "        with rasterio.open(path) as src:\n",
        "            rgb = src.read([1, 2, 3]).astype(\"float32\")\n",
        "            rgb = rgb / (rgb.max() + 1e-6)          # normalize for display\n",
        "            rgb = rgb.transpose(1, 2, 0)            # (rows, cols, bands)\n",
        "\n",
        "        ax.imshow(rgb)\n",
        "        ax.set_title(label, fontsize=14)\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "        # Panel letter (A, B, C...)\n",
        "        ax.text(\n",
        "            0.02, 0.98, chr(ord(\"A\") + i),\n",
        "            transform=ax.transAxes,\n",
        "            va=\"top\", ha=\"left\",\n",
        "            fontsize=14,\n",
        "            bbox=dict(facecolor=\"white\", alpha=0.7, edgecolor=\"none\", pad=3)\n",
        "        )\n",
        "    else:\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "fig.suptitle(\"Landsat RGB ‚Äî Download + Crop\", fontsize=18)\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "IUJ-4QKnWW0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we get into the segmentation techniques, let us first define a repeatable function for plotting two images side-by-side for easy comparison."
      ],
      "metadata": {
        "id": "HAINr1XwQp12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Create simple matplotlib function for side-by-side pair comparison\n",
        "def show_pair(original, segmented, title, cmap=None):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(11, 4))\n",
        "    axes[0].imshow(original)\n",
        "    axes[0].set_title(\"Original\")\n",
        "    axes[0].axis(\"off\")\n",
        "\n",
        "    if segmented.ndim == 2:\n",
        "        axes[1].imshow(segmented, cmap=cmap or \"gray\")\n",
        "    else:\n",
        "        axes[1].imshow(segmented)\n",
        "    axes[1].set_title(title)\n",
        "    axes[1].axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "YcYFr6-dQnnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Otsu thresholding\n",
        "\n",
        "Segmentation approach:\n",
        "- Splits a grayscale image into foreground and background regions.\n",
        "- Automatically selects a threshold based on the image intensity histogram.\n",
        "\n",
        "Otsu selects the threshold that splits the image into two substantial groups, maximizing the distance between their average intensities.  \n",
        "\n",
        "Hence, we find the threshold that best separates foreground from background based on histogram structure.\n"
      ],
      "metadata": {
        "id": "XCSMjMmRaiwo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key parameters:\n",
        "- No manual threshold required.\n",
        "- Input quality depends on histogram separation.\n",
        "\n",
        "Key papers:\n",
        "- Otsu, N. (1979). *A Threshold Selection Method from Gray-Level Histograms*. IEEE Trans. SMC, 9(1), 62-66.\n",
        "- Sezgin, M., & Sankur, B. (2004). *Survey over image thresholding techniques and quantitative performance evaluation*. J. Electronic Imaging, 13(1), 146-165."
      ],
      "metadata": {
        "id": "EFwgIUJ2cVHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Apply Otsu threshold and show side-by-side comparison\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.filters import threshold_otsu\n",
        "\n",
        "# Select an image as initial example\n",
        "path = \"data_landsat/cropped/ames_ia_rgb_cropped.tif\"\n",
        "\n",
        "# Load RGB image (.tif)\n",
        "with rasterio.open(path) as src:\n",
        "    rgb = src.read([1, 2, 3]).astype(\"float32\").transpose(1, 2, 0)\n",
        "\n",
        "# Normalize for display (max values should be ~1)\n",
        "rgb = rgb / (np.nanmax(rgb) + 1e-6) # 1e-6 is to avoid zero division\n",
        "\n",
        "# Apply Otsu\n",
        "gray = rgb2gray(rgb) # RGB to single band grayscale image\n",
        "t = threshold_otsu(gray) # maximizing the variance between two classes\n",
        "mask = gray > t # 1 = foreground, 0 = background\n",
        "\n",
        "otsu_vis = rgb.copy()\n",
        "otsu_vis[~mask] *= 0.25  # dim only background pixels\n",
        "\n",
        "show_pair(rgb, otsu_vis, f\"Otsu Threshold (t={t:.3f})\")"
      ],
      "metadata": {
        "id": "N61TXzDLQ9jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Inspect Otsu pixel histogram threshold\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.filters import threshold_otsu\n",
        "\n",
        "path = cropped_tifs[0]\n",
        "\n",
        "with rasterio.open(path) as src:\n",
        "    rgb = src.read([1, 2, 3]).astype(\"float32\").transpose(1, 2, 0)\n",
        "\n",
        "rgb = rgb / (np.nanmax(rgb) + 1e-6)\n",
        "gray = rgb2gray(rgb)\n",
        "\n",
        "t = threshold_otsu(gray)\n",
        "mask = gray > t\n",
        "\n",
        "otsu_vis = rgb.copy()\n",
        "otsu_vis[~mask] *= 0.25\n",
        "\n",
        "g = gray[np.isfinite(gray)].ravel()\n",
        "thr = np.atleast_1d(t).astype(float)\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.hist(g, bins=256, density=True)\n",
        "for t in thr:\n",
        "    plt.axvline(t, linewidth=2, color='red')\n",
        "plt.title(f\"Otsu histogram (t={t:.3f} - indicated in red)\")\n",
        "plt.xlabel(\"Pixel intensity (grayscale)\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "e5sIosmogFsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Now apply Otsu threshold for all five images\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.filters import threshold_otsu\n",
        "\n",
        "image_files = cropped_tifs[:5]  # your cropped GeoTIFFs\n",
        "\n",
        "fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(6, 12))\n",
        "plt.subplots_adjust(hspace=0.25, wspace=0.05)\n",
        "\n",
        "for row, path in enumerate(image_files):\n",
        "\n",
        "    # --- Load GeoTIFF properly ---\n",
        "    with rasterio.open(path) as src:\n",
        "        rgb = src.read([1, 2, 3]).astype(\"float32\")  # (3, H, W)\n",
        "        rgb = rgb.transpose(1, 2, 0)                 # (H, W, 3)\n",
        "\n",
        "    # Normalize for display\n",
        "    rgb = rgb / (np.nanmax(rgb) + 1e-6)\n",
        "\n",
        "    # --- Otsu threshold ---\n",
        "    gray = rgb2gray(rgb)\n",
        "    t = threshold_otsu(gray)\n",
        "    mask = gray > t\n",
        "\n",
        "    # Dim background for visualization\n",
        "    otsu_vis = rgb.copy()\n",
        "    otsu_vis[~mask] *= 0.25\n",
        "\n",
        "    # Label\n",
        "    label = path.stem.replace(\"_rgb_cropped\", \"\").replace(\"_\", \" \").title()\n",
        "\n",
        "    # --- Plot original ---\n",
        "    axL = axes[row, 0]\n",
        "    axL.imshow(rgb)\n",
        "    axL.set_title(f\"{label}\", fontsize=12)\n",
        "    axL.axis(\"off\")\n",
        "\n",
        "    # --- Plot Otsu result ---\n",
        "    axR = axes[row, 1]\n",
        "    axR.imshow(otsu_vis)\n",
        "    axR.set_title(f\"Otsu Threshold\", fontsize=12)\n",
        "    axR.axis(\"off\")\n",
        "\n",
        "fig.suptitle(\"Landsat RGB (Left) vs Otsu Segmentation (Right)\", fontsize=16)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hWRmwRpqcQUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Writing segments to a geopackage\n",
        "import os\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from rasterio.features import shapes\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import shape\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.filters import threshold_otsu\n",
        "\n",
        "path_in = \"data_landsat/cropped/ames_ia_rgb_cropped.tif\"\n",
        "folder_out = \"data_landsat/shapes\"\n",
        "os.makedirs(folder_out, exist_ok=True)   # Create our directory\n",
        "path_out = os.path.join(folder_out, \"agriculture_iowa_ames_shapes_cropped.gpkg\")\n",
        "\n",
        "with rasterio.open(path_in) as src:\n",
        "\n",
        "    rgb = src.read([1, 2, 3]).astype(\"float32\").transpose(1, 2, 0)\n",
        "\n",
        "    # Normalize maximum values to ~1.\n",
        "    rgb = rgb / (np.nanmax(rgb) + 1e-6) # 1e-6 prevents division by zero errors\n",
        "\n",
        "    # Apply Otsu\n",
        "    gray = rgb2gray(rgb)\n",
        "    t = threshold_otsu(gray)\n",
        "    mask = (gray > t).astype(np.uint8)  # 1 = foreground, 0 = background\n",
        "\n",
        "    transform = src.transform\n",
        "    crs = src.crs\n",
        "\n",
        "# Convert mask to polygons via geodataframe (gdf) and export\n",
        "geoms = []\n",
        "vals = []\n",
        "for geom, val in shapes(mask, mask=(mask == 1), transform=transform):\n",
        "    geoms.append(shape(geom))\n",
        "    vals.append(int(val))\n",
        "gdf = gpd.GeoDataFrame({\"class\": vals}, geometry=geoms, crs=crs)\n",
        "gdf.to_file(path_out, driver=\"GPKG\") # Export shapes to .gpkg\n",
        "\n",
        "# Show final side-by-side plot\n",
        "show_pair(rgb, mask, \"Otsu (single) mask layer\")"
      ],
      "metadata": {
        "id": "CEbVkZwsDSMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Otsu thresholding (3 classes)\n",
        "\n",
        "Segmentation approach:\n",
        "- Extends Otsu to multiple classes.\n",
        "- Useful for coarse land-cover partitioning (dark/mid/bright regions).\n",
        "\n"
      ],
      "metadata": {
        "id": "l9Jshb1NeB5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key parameters:\n",
        "- `classes=3` (can also try 4 or 5).\n",
        "- Sensitive to histogram shape and contrast."
      ],
      "metadata": {
        "id": "5gTaZ2xNTTnn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key papers:\n",
        "- Otsu, N. (1979). *A Threshold Selection Method from Gray-Level Histograms*. IEEE Trans. SMC, 9(1), 62-66.\n",
        "- Liao, P.-S., Chen, T.-S., & Chung, P.-C. (2001). *A fast algorithm for multilevel thresholding*. JISE, 17(5), 713-727.\n",
        "\n"
      ],
      "metadata": {
        "id": "kk6OfE0ueB5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Multi-Otsu thresholding\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.filters import threshold_multiotsu\n",
        "\n",
        "# Select one image\n",
        "path = \"data_landsat/cropped/los_angeles_ca_rgb_cropped.tif\"\n",
        "\n",
        "# Load RGB image\n",
        "with rasterio.open(path) as src:\n",
        "    rgb = src.read([1, 2, 3]).astype(\"float32\").transpose(1, 2, 0)\n",
        "\n",
        "# Normalize\n",
        "rgb = rgb / (np.nanmax(rgb) + 1e-6)\n",
        "\n",
        "# Apply Multi-Otsu (3 classes)\n",
        "gray = rgb2gray(rgb)\n",
        "t1, t2 = threshold_multiotsu(gray, classes=3)\n",
        "\n",
        "seg = np.digitize(gray, bins=[t1, t2])\n",
        "\n",
        "# Visualization: overlay the 3-class segmentation on the RGB\n",
        "vis = (rgb * 0.35).copy() # Start from a  dimmed version of the original\n",
        "# Colorize each class\n",
        "vis[seg == 0] = [0.10, 0.20, 0.80]  # blue # class 0 = dark pixels\n",
        "vis[seg == 1] = [0.20, 0.80, 0.20]  # green # class 1 = mid pixels\n",
        "vis[seg == 2] = [0.90, 0.20, 0.20]  # red # class 2 = bright pixels\n",
        "\n",
        "# Plot\n",
        "show_pair(rgb, vis, f\"Multi-Otsu (3 classes)\\nt1={t1:.3f}, t2={t2:.3f}\")"
      ],
      "metadata": {
        "id": "83JY1CMwTqJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.filters import threshold_multiotsu\n",
        "\n",
        "t1, t2 = threshold_multiotsu(gray, classes=3)\n",
        "seg = np.digitize(gray, bins=[t1, t2]).astype(np.uint8)\n",
        "\n",
        "# simple visualization (optional)\n",
        "vis = (rgb * 0.35).copy()\n",
        "vis[seg == 0] = [0.10, 0.20, 0.80]\n",
        "vis[seg == 1] = [0.20, 0.80, 0.20]\n",
        "vis[seg == 2] = [0.90, 0.20, 0.20]\n",
        "\n",
        "# show_pair(rgb, vis, f\"Multi-Otsu (t1={t1:.3f}, t2={t2:.3f})\")\n",
        "# show_hist_with_thresholds(gray, [t1, t2], title=\"Multi-Otsu histogram (3 classes)\")\n",
        "\n",
        "g = gray[np.isfinite(gray)].ravel()\n",
        "thr = np.atleast_1d([t1, t2]).astype(float)\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.hist(g, bins=256, density=True)\n",
        "for t in thr:\n",
        "    plt.axvline(t, linewidth=2, color=\"red\")\n",
        "plt.title(\"Multi-Otsu histogram (3 classes, divided by red thresholds)\")\n",
        "plt.xlabel(\"Pixel intensity (grayscale)\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "DxhvUHJnh26h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Now apply multi-Otsu threshold for all five images\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.filters import threshold_multiotsu\n",
        "\n",
        "image_files = cropped_tifs[:5]  # your cropped GeoTIFFs\n",
        "\n",
        "fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(6, 12))\n",
        "plt.subplots_adjust(hspace=0.25, wspace=0.05)\n",
        "\n",
        "for row, path in enumerate(image_files):\n",
        "\n",
        "    # Load GeoTIFF properly\n",
        "    with rasterio.open(path) as src:\n",
        "        rgb = src.read([1, 2, 3]).astype(\"float32\")  # (3, H, W)\n",
        "        rgb = rgb.transpose(1, 2, 0)                 # (H, W, 3)\n",
        "\n",
        "    # Normalize for display\n",
        "    rgb = rgb / (np.nanmax(rgb) + 1e-6)\n",
        "\n",
        "    # Multi-Otsu threshold (3 classes)\n",
        "    gray = rgb2gray(rgb)\n",
        "\n",
        "    # thresholds will have length classes-1 = 2\n",
        "    t1, t2 = threshold_multiotsu(gray, classes=3)\n",
        "\n",
        "    # Convert grayscale into class labels: 0,1,2\n",
        "    seg = np.digitize(gray, bins=[t1, t2])\n",
        "\n",
        "    # Visualization: overlay the 3-class segmentation on the RGB\n",
        "    vis = (rgb * 0.35).copy() # Start from a  dimmed version of the original\n",
        "    # Colorize each class\n",
        "    vis[seg == 0] = [0.10, 0.20, 0.80]  # blue # class 0 = dark pixels\n",
        "    vis[seg == 1] = [0.20, 0.80, 0.20]  # green # class 1 = mid pixels\n",
        "    vis[seg == 2] = [0.90, 0.20, 0.20]  # red # class 2 = bright pixels\n",
        "\n",
        "    # Label\n",
        "    label = path.stem.replace(\"_rgb_cropped\", \"\").replace(\"_\", \" \").title()\n",
        "\n",
        "    # --- Plot original ---\n",
        "    axL = axes[row, 0]\n",
        "    axL.imshow(rgb)\n",
        "    axL.set_title(f\"{label}\", fontsize=12)\n",
        "    axL.axis(\"off\")\n",
        "\n",
        "    # --- Plot Multi-Otsu result ---\n",
        "    axR = axes[row, 1]\n",
        "    axR.imshow(vis)\n",
        "    axR.set_title(f\"{label} ‚Äî Multi-Otsu (3 classes)\", fontsize=12)\n",
        "    axR.axis(\"off\")\n",
        "\n",
        "    # Optional: show thresholds in the console\n",
        "    print(f\"{label}: t1={t1:.3f}, t2={t2:.3f}\")\n",
        "\n",
        "fig.suptitle(\"Landsat RGB (Left) vs Multi-Otsu 3-Class Segmentation (Right)\", fontsize=16)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "DU3_iaHUfDPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Writing segments to a geopackage\n",
        "import os\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from rasterio.features import shapes\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import shape\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.filters import threshold_multiotsu\n",
        "\n",
        "path_in = \"data_landsat/cropped/los_angeles_ca_rgb_cropped.tif\"\n",
        "folder_out = \"data_landsat/shapes\"\n",
        "os.makedirs(folder_out, exist_ok=True)   # Create our directory\n",
        "path_out = os.path.join(folder_out, \"los_angeles_ca_rgb_cropped.gpkg\")\n",
        "\n",
        "with rasterio.open(path_in) as src:\n",
        "\n",
        "    rgb = src.read([1, 2, 3]).astype(\"float32\").transpose(1, 2, 0)\n",
        "\n",
        "    # Normalize maximum values to ~1.\n",
        "    rgb = rgb / (np.nanmax(rgb) + 1e-6) # 1e-6 prevents division by zero errors\n",
        "\n",
        "    # Multi-Otsu (3 classes)\n",
        "    gray = rgb2gray(rgb)\n",
        "    t1, t2 = threshold_multiotsu(gray, classes=3)\n",
        "\n",
        "    # Class labels: 0, 1, 2\n",
        "    seg = np.digitize(gray, bins=[t1, t2]).astype(np.uint8)\n",
        "\n",
        "    transform = src.transform\n",
        "    crs = src.crs\n",
        "\n",
        "# Convert segmentation to polygons (keeps class value per polygon)\n",
        "geoms = []\n",
        "classes = []\n",
        "for geom, val in shapes(seg, transform=transform):\n",
        "    geoms.append(shape(geom))\n",
        "    classes.append(int(val))\n",
        "gdf = gpd.GeoDataFrame({\"class\": classes}, geometry=geoms, crs=crs)\n",
        "gdf.to_file(path_out, driver=\"GPKG\") # Export shapes to .gpkg\n",
        "\n",
        "# Visualization: overlay the 3-class segmentation on the RGB\n",
        "vis = (rgb * 0.35).copy() # Start from a  dimmed version of the original\n",
        "# Colorize each class\n",
        "vis[seg == 0] = [0.10, 0.20, 0.80]  # blue # class 0 = dark pixels\n",
        "vis[seg == 1] = [0.20, 0.80, 0.20]  # green # class 1 = mid pixels\n",
        "vis[seg == 2] = [0.90, 0.20, 0.20]  # red # class 2 = bright pixels\n",
        "\n",
        "# Show final side-by-side plot\n",
        "show_pair(rgb, vis, \"Multi-Otsu mask layer\")"
      ],
      "metadata": {
        "id": "hVCwlv5pYHRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Viewing close up of New Orleans Multi-Otsu\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.filters import threshold_multiotsu\n",
        "\n",
        "path = \"data_landsat/cropped/new_orleans_la_rgb_cropped.tif\"\n",
        "\n",
        "# Load GeoTIFF\n",
        "with rasterio.open(path) as src:\n",
        "    rgb = src.read([1, 2, 3]).astype(\"float32\")\n",
        "    rgb = rgb.transpose(1, 2, 0)\n",
        "\n",
        "# Normalize\n",
        "rgb = rgb / (np.nanmax(rgb) + 1e-6)\n",
        "\n",
        "# Multi-Otsu (3 classes)\n",
        "gray = rgb2gray(rgb)\n",
        "thresholds = threshold_multiotsu(gray, classes=3)\n",
        "seg = np.digitize(gray, bins=thresholds)\n",
        "\n",
        "# Plot full-size\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(seg, cmap=\"viridis\")\n",
        "plt.title(\"New Orleans ‚Äî Multi-Otsu (3 Classes)\", fontsize=16)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"Thresholds: {thresholds}\")"
      ],
      "metadata": {
        "id": "p5z6l2fQf3HB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-means (RGB clustering)\n",
        "\n",
        "Segmentation approach:\n",
        "- Clusters pixels in color space.\n",
        "- Each pixel is assigned to nearest color centroid.\n",
        "\n",
        "So, K-means segmentation groups pixels based on similarity in color space.\n",
        "\n",
        "For RGB images:\n",
        "- Each pixel is treated as a 3D vector (see 3D plot below where each pixel conforms to $\n",
        "  x_i = [R_i, G_i, B_i]\n",
        "  $).\n",
        "- Hence, pixels are clustered in this 3D space.\n",
        "- Each pixel is assigned to the nearest cluster centroid.\n",
        "\n",
        "Unlike Otsu (which uses intensity only), K-means operates in multivariate feature space."
      ],
      "metadata": {
        "id": "vKmsB_nIgQyX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key parameters:\n",
        "- `k`: number of clusters.\n",
        "- Iterations and initialization affect stability.\n"
      ],
      "metadata": {
        "id": "YbJzxo0wcb-i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key papers:\n",
        "- MacQueen, J. (1967). *Some Methods for classification and Analysis of Multivariate Observations*. Proc. 5th Berkeley Symposium.\n",
        "- Lloyd, S. (1982). *Least squares quantization in PCM*. IEEE Trans. Information Theory, 28(2), 129-137."
      ],
      "metadata": {
        "id": "9XqC3gQvgQyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import rasterio\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Select one image\n",
        "path = cropped_tifs[0]\n",
        "\n",
        "# Load RGB\n",
        "with rasterio.open(path) as src:\n",
        "    rgb = src.read([1, 2, 3]).astype(np.float32).transpose(1, 2, 0)\n",
        "\n",
        "# Percentile stretch to uint8 (pixel value normalization)\n",
        "p2, p98 = np.nanpercentile(rgb, (2, 98))\n",
        "rgb01 = np.clip((rgb - p2) / (p98 - p2 + 1e-6), 0, 1)\n",
        "rgb8 = (rgb01 * 255).astype(np.uint8)\n",
        "\n",
        "# K-means using scikit-learn\n",
        "h, w, _ = rgb8.shape\n",
        "X = rgb8.reshape(-1, 3)\n",
        "\n",
        "k = 5\n",
        "kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "labels = kmeans.fit_predict(X)\n",
        "\n",
        "# Replace each pixel with its centroid color\n",
        "segmented = kmeans.cluster_centers_[labels].reshape(h, w, 3).astype(np.uint8)\n",
        "\n",
        "# Show result\n",
        "show_pair(rgb8, segmented, f\"K-means RGB (k={k})\")\n"
      ],
      "metadata": {
        "id": "2VuLmFN2dxiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are able to explore the number of pixels which fall in each group, which helps to inform us whether:\n",
        "\n",
        "* The clusters are balanced\n",
        "* One cluster dominates\n",
        "* If k is too large (clusters become too small)\n",
        "\n",
        "We can do that as follows:"
      ],
      "metadata": {
        "id": "ed1UcB2pizrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Exploring cluster size distribution and centroid colors\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "counts = np.bincount(labels)\n",
        "plt.figure(figsize=(6,4))  # Plot k-means cluster sizes\n",
        "plt.bar(range(k), counts)\n",
        "plt.xlabel(\"Cluster ID\")\n",
        "plt.ylabel(\"Number of Pixels\")\n",
        "plt.title(\"K-means Cluster Sizes\")\n",
        "plt.show()\n",
        "\n",
        "centroids = kmeans.cluster_centers_.astype(np.uint8)\n",
        "plt.figure(figsize=(8,2))  # Plot color of cluster centroids\n",
        "plt.imshow([centroids])\n",
        "plt.yticks([])\n",
        "plt.xticks(range(k))\n",
        "plt.title(\"Cluster Centroid Colors\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Anty1AHLiqv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If it is still not clear how the Otsu methods are one dimensional (1D), and k-means is three dimensional (3D), see the 3D plot below to illustrate the concept.\n",
        "\n",
        "Pixels are plotted based on the r, g, b values, against axis x, y, z."
      ],
      "metadata": {
        "id": "fxke_Ee7m1P0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Plot the pixels in 3D space (for red, green, blue values)\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "sample_idx = np.random.choice(X.shape[0], size=5000, replace=False)\n",
        "X_sample = X[sample_idx]\n",
        "labels_sample = labels[sample_idx]\n",
        "\n",
        "fig = plt.figure(figsize=(8,7))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(X_sample[:,0], X_sample[:,1], X_sample[:,2],\n",
        "           c=labels_sample, s=2)\n",
        "ax.set_xlabel(\"R\")\n",
        "ax.set_ylabel(\"G\")\n",
        "ax.set_zlabel(\"B\", rotation=0, labelpad=1)\n",
        "\n",
        "plt.title(\"K-means clusters in 3D RGB space\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Yf_ZCi9JjIYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: K-means RGB segmentation for all 5 images\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Apply to all 5 cropped GeoTIFFs and then plot\n",
        "image_files = cropped_tifs[:5]\n",
        "\n",
        "# Set up our matplotlib plot\n",
        "fig, axes = plt.subplots(nrows=len(image_files), ncols=2, figsize=(6, 12))\n",
        "plt.subplots_adjust(hspace=0.25, wspace=0.05)\n",
        "\n",
        "k = 5 # Number of desired clusters\n",
        "\n",
        "for row, path in enumerate(image_files):\n",
        "\n",
        "    # Read GeoTIFF (bands, H, W) -> (H, W, 3)\n",
        "    with rasterio.open(path) as src:\n",
        "        rgb = src.read([1, 2, 3]).astype(np.float32).transpose(1, 2, 0)\n",
        "\n",
        "    # Percentile stretch to uint8 for display + clustering\n",
        "    p2, p98 = np.nanpercentile(rgb, (2, 98))\n",
        "    rgb01 = np.clip((rgb - p2) / (p98 - p2 + 1e-6), 0, 1)\n",
        "    rgb8 = (rgb01 * 255).astype(np.uint8)\n",
        "\n",
        "    # K-means (scikit-learn)\n",
        "    h, w, _ = rgb8.shape\n",
        "    X = rgb8.reshape(-1, 3)\n",
        "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    labels = km.fit_predict(X)\n",
        "    kmeans_rgb = km.cluster_centers_[labels].reshape(h, w, 3).astype(np.uint8)\n",
        "    label = path.stem.replace(\"_rgb_cropped\", \"\").replace(\"_\", \" \").title()\n",
        "\n",
        "    # Left: original\n",
        "    axL = axes[row, 0]\n",
        "    axL.imshow(rgb8)\n",
        "    axL.set_title(f\"{label}\", fontsize=12)\n",
        "    axL.axis(\"off\")\n",
        "\n",
        "    # Right: k-means quantized\n",
        "    axR = axes[row, 1]\n",
        "    axR.imshow(kmeans_rgb)\n",
        "    axR.set_title(f\"K-means (k={k})\", fontsize=12)\n",
        "    axR.axis(\"off\")\n",
        "\n",
        "fig.suptitle(\"Landsat RGB (Left) vs K-means RGB Clustering (Right)\", fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tnUYDRgmiiiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Linear Iterative Clustering (SLIC) superpixels\n",
        "\n",
        "Simple Linear Iterative Clustering (SLIC) groups pixels using a combined color + spatial distance metric.\n",
        "\n",
        "By \"superpixels\" we are referring to regionally aggregated areas, based on the underlying pixel values.\n",
        "\n",
        "Segmentation approach:\n",
        "- Groups nearby pixels into compact superpixels.\n",
        "- Balances color similarity and spatial proximity.\n",
        "\n",
        "You can think of SLIC as k-means taking place in 5D space, where we develop a 5D feature vector ($\\mathbf{f}_i$) as follows:\n",
        "\n",
        "$$\n",
        "\\mathbf{f}_i = (L_i, a_i, b_i, x_i, y_i)\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "- $(L_i, a_i, b_i$) are the pixel values in CIELAB color space.\n",
        "- $(x_i, y_i$) are the spatial coordinates of the pixel.\n",
        "\n",
        "Note, CIELAB is the color space defined by the International Commission on Illumination (CIE) consisting of $L*a*b*$."
      ],
      "metadata": {
        "id": "HU852ohajoua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key parameters:\n",
        "- `n_segments`: number of superpixels.\n",
        "- `compactness`: spatial regularity vs boundary adherence.\n",
        "\n",
        "\n",
        "Key papers:\n",
        "- Achanta, R., et al. (2012). *SLIC Superpixels Compared to State-of-the-art Superpixel Methods*. IEEE TPAMI, 34(11), 2274-2282.\n",
        "- Stutz, D., Hermans, A., & Leibe, B. (2018). *Superpixels: An Evaluation of the State-of-the-Art*. CVIU, 166, 1-27."
      ],
      "metadata": {
        "id": "Xl8YJgYSjoua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import rasterio\n",
        "from skimage.segmentation import slic, mark_boundaries\n",
        "\n",
        "# Select one image\n",
        "path = \"data_landsat/cropped/phoenix_az_rgb_cropped.tif\"\n",
        "\n",
        "# Load RGB ---\n",
        "with rasterio.open(path) as src:\n",
        "    rgb = src.read([1, 2, 3]).astype(np.float32).transpose(1, 2, 0)\n",
        "\n",
        "# Percentile stretch -> [0,1] float (helps SLIC + display)\n",
        "p2, p98 = np.nanpercentile(rgb, (2, 98))\n",
        "rgb_float = np.clip((rgb - p2) / (p98 - p2 + 1e-6), 0, 1)\n",
        "\n",
        "# SLIC superpixels function from sci-kit image\n",
        "slic_labels = slic(\n",
        "    rgb_float,\n",
        "    n_segments=250,\n",
        "    compactness=12.0,\n",
        "    sigma=1.0,\n",
        "    start_label=1\n",
        ")\n",
        "\n",
        "# Overlay boundaries on the image\n",
        "overlay = mark_boundaries(rgb_float, slic_labels, color=(1, 1, 0))\n",
        "\n",
        "# Show before/after using show_pair()\n",
        "show_pair(rgb_float, overlay, \"SLIC boundaries for Phoenix, AZ\")\n"
      ],
      "metadata": {
        "id": "PrQeC__Mq8aM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can view the superpixel label map to get a better view of regional partitioning processes."
      ],
      "metadata": {
        "id": "DORi1vWUvW_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Superpixel label map\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.imshow(slic_labels, cmap=\"tab20\")\n",
        "plt.title(\"SLIC Label Map (Superpixel IDs)\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cy_FRFPZuAGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importantly, the SLIC starts from a regular grid before iterative refinement, as illustrated below."
      ],
      "metadata": {
        "id": "6n0I57UCvzBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Initial SLIC grid\n",
        "h, w = rgb_float.shape[:2]\n",
        "S = int(np.sqrt((h*w)/250))  # example approximate grid spacing\n",
        "\n",
        "plt.imshow(rgb_float)\n",
        "for y in range(0, h, S):\n",
        "    plt.axhline(y)\n",
        "for x in range(0, w, S):\n",
        "    plt.axvline(x)\n",
        "plt.title(\"Example approximate initial grid (before iteration)\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "s7ASGSSauM--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Be aware there are other parameters which affect the partitioning process, including compactness.\n",
        "\n",
        "View the example below to understand how this affects the image."
      ],
      "metadata": {
        "id": "GeWBY8N6wC0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Comparing different compactness values\n",
        "labels_low = slic(rgb_float, n_segments=250, compactness=8)\n",
        "labels_high = slic(rgb_float, n_segments=250, compactness=30)\n",
        "\n",
        "overlay_low = mark_boundaries(rgb_float, labels_low)\n",
        "overlay_high = mark_boundaries(rgb_float, labels_high)\n",
        "\n",
        "show_pair(overlay_low, overlay_high,\"Low compactness (left) vs High compactness (right)\")\n"
      ],
      "metadata": {
        "id": "i5gGWHWGuOZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "See the feature space vector below (`features`), which when printed shows the five values (for the spatial coordinates and RGB values)."
      ],
      "metadata": {
        "id": "SKc36l3WwatM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Inspect the feature space\n",
        "h, w = rgb_float.shape[:2]\n",
        "xx, yy = np.meshgrid(np.arange(w), np.arange(h))\n",
        "\n",
        "features = np.dstack([rgb_float, xx / w, yy / h])\n",
        "\n",
        "print(features[1])"
      ],
      "metadata": {
        "id": "smCETnFHu_jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can replace each superpixel with its mean color to simplify the image, and conceptually illustrate SLIC."
      ],
      "metadata": {
        "id": "IdhYXB_exkD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Color superpixels with the mean color in each\n",
        "recon = np.zeros_like(rgb_float)\n",
        "\n",
        "for label in np.unique(slic_labels):\n",
        "    mask = slic_labels == label\n",
        "    recon[mask] = rgb_float[mask].mean(axis=0)\n",
        "\n",
        "show_pair(rgb_float, recon, \"Original vs Superpixel Mean Color\")\n"
      ],
      "metadata": {
        "id": "tF7NiNW1xDq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Apply SLIC approach to all five images\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "\n",
        "from skimage.segmentation import slic, mark_boundaries\n",
        "\n",
        "image_files = cropped_tifs[:5]\n",
        "\n",
        "fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(6, 12))\n",
        "plt.subplots_adjust(hspace=0.25, wspace=0.05)\n",
        "\n",
        "for row, path in enumerate(image_files):\n",
        "\n",
        "    # Load GeoTIFF\n",
        "    with rasterio.open(path) as src:\n",
        "        rgb = src.read([1, 2, 3]).astype(np.float32).transpose(1, 2, 0)\n",
        "\n",
        "    # Percentile stretch -> [0,1] float (helps SLIC + display)\n",
        "    p2, p98 = np.nanpercentile(rgb, (2, 98))\n",
        "    rgb_float = np.clip((rgb - p2) / (p98 - p2 + 1e-6), 0, 1)\n",
        "\n",
        "    # SLIC superpixels\n",
        "    slic_labels = slic(\n",
        "        rgb_float,\n",
        "        n_segments=250,\n",
        "        compactness=12.0,\n",
        "        sigma=1.0,\n",
        "        start_label=1\n",
        "    )\n",
        "\n",
        "    # Draw boundaries on top of the image (yellow-ish boundary color)\n",
        "    boundary_overlay = mark_boundaries(rgb_float, slic_labels, color=(1, 1, 0))\n",
        "\n",
        "    # Label\n",
        "    label = path.stem.replace(\"_rgb_cropped\", \"\").replace(\"_\", \" \").title()\n",
        "\n",
        "    # Plot original\n",
        "    axL = axes[row, 0]\n",
        "    axL.imshow(rgb_float)\n",
        "    axL.set_title(f\"{label}\", fontsize=12)\n",
        "    axL.axis(\"off\")\n",
        "\n",
        "    # Plot superpixels overlay\n",
        "    axR = axes[row, 1]\n",
        "    axR.imshow(boundary_overlay)\n",
        "    axR.set_title(f\"SLIC superpixels\", fontsize=12)\n",
        "    axR.axis(\"off\")\n",
        "\n",
        "fig.suptitle(\"Landsat RGB (Left) vs SLIC Superpixels (Right)\", fontsize=16)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aQx3dOsRkxoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Watershed segmentation\n",
        "\n",
        "Watershed segmentation finds region boundaries by simulating how water would fill intensity basins in an image.\n",
        "\n",
        "This segmentation approach:\n",
        "- Treats the gradient magnitude in an image as a topographic surface and performs \"region flooding\" from predefined markers.\n",
        "- Produces region boundaries from gradient basins.\n",
        "\n",
        "Think of this as pouring water onto a surface, with the water filling up the low areas first. Where water from different basins meets, you build a dam (e.g., treating the image like a \"topographic surface\").\n",
        "\n",
        "Brighter pixels represent higher elevations, and darker pixels represent lower elevations."
      ],
      "metadata": {
        "id": "6O5-vKoblTz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key parameters:\n",
        "- Marker strategy strongly affects output.\n",
        "- `min_distance` in peak detection controls seed density.\n",
        "\n",
        "\n",
        "Key papers:\n",
        "- Vincent, L., & Soille, P. (1991). *Watersheds in digital spaces: An efficient algorithm based on immersion simulations*. IEEE TPAMI, 13(6), 583-598.\n",
        "- Roerdink, J. B. T. M., & Meijster, A. (2000). *The Watershed Transform: Definitions, Algorithms and Parallelization Strategies*. Fundamenta Informaticae, 41, 187-228."
      ],
      "metadata": {
        "id": "7IE4vmv4lTz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Watershed analysis\n",
        "\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from scipy import ndimage as ndi\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.feature import peak_local_max\n",
        "from skimage.filters import sobel, threshold_otsu\n",
        "from skimage.segmentation import watershed, mark_boundaries\n",
        "\n",
        "# Pick one image\n",
        "path = \"data_landsat/cropped/mt_jefferson_or_rgb_cropped.tif\"\n",
        "\n",
        "# Load + normalize to [0,1]\n",
        "with rasterio.open(path) as src:\n",
        "    rgb = src.read([1, 2, 3]).astype(np.float32).transpose(1, 2, 0)\n",
        "p2, p98 = np.nanpercentile(rgb, (2, 98))\n",
        "rgb = np.clip((rgb - p2) / (p98 - p2 + 1e-6), 0, 1)\n",
        "\n",
        "# Watershed (minimal pipeline)\n",
        "gray = rgb2gray(rgb)\n",
        "mask = gray > threshold_otsu(gray)\n",
        "dist = ndi.distance_transform_edt(mask)\n",
        "coords = peak_local_max(dist, min_distance=15, labels=mask)\n",
        "markers = np.zeros_like(gray, dtype=np.int32)\n",
        "markers[tuple(coords.T)] = np.arange(1, len(coords) + 1) if len(coords) else 1\n",
        "markers = ndi.label(markers > 0)[0]\n",
        "labels = watershed(sobel(gray), markers, mask=mask)\n",
        "\n",
        "# Overlay boundaries + plot\n",
        "overlay = mark_boundaries(rgb, labels, color=(1, 0, 0))\n",
        "show_pair(rgb, overlay, \"Watershed (boundaries)\")\n"
      ],
      "metadata": {
        "id": "T4yn0OYyyvUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following panel plot shows the intermediate steps for how this is achieved:\n",
        "\n",
        "* Grayscale - This is the essentially the height map\n",
        "* Gradient - Edges become mountains, with flooding avoids crossing these ridges\n",
        "* Mask - We only segment where we think the object area is\n",
        "* Distance transform - Centers of objects are deepest basins\n",
        "* Markers - These are the starting points for flooding\n",
        "* Overlay - Dams where floods meet boundaries"
      ],
      "metadata": {
        "id": "KD41iDeL2Rrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Intermediate steps\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "from scipy import ndimage as ndi\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.filters import sobel, threshold_otsu\n",
        "from skimage.feature import peak_local_max\n",
        "from skimage.segmentation import watershed, mark_boundaries\n",
        "\n",
        "# pick one image\n",
        "path = \"data_landsat/cropped/mt_jefferson_or_rgb_cropped.tif\"\n",
        "\n",
        "# load + normalize\n",
        "with rasterio.open(path) as src:\n",
        "    rgb = src.read([1, 2, 3]).astype(np.float32).transpose(1, 2, 0)\n",
        "p2, p98 = np.nanpercentile(rgb, (2, 98))\n",
        "rgb = np.clip((rgb - p2) / (p98 - p2 + 1e-6), 0, 1)\n",
        "\n",
        "# 1) terrain\n",
        "gray = rgb2gray(rgb)\n",
        "\n",
        "# 2) ridges\n",
        "grad = sobel(gray)\n",
        "\n",
        "# 3) mask + distance (basins)\n",
        "t = threshold_otsu(gray)\n",
        "mask = gray > t\n",
        "dist = ndi.distance_transform_edt(mask)\n",
        "\n",
        "# 4) markers (seeds)\n",
        "coords = peak_local_max(dist, min_distance=15, labels=mask)\n",
        "markers = np.zeros_like(gray, dtype=np.int32)\n",
        "if len(coords):\n",
        "    markers[tuple(coords.T)] = np.arange(1, len(coords) + 1)\n",
        "else:\n",
        "    markers[gray.shape[0]//2, gray.shape[1]//2] = 1\n",
        "markers = ndi.label(markers > 0)[0]\n",
        "\n",
        "# 5) watershed result\n",
        "labels = watershed(grad, markers, mask=mask)\n",
        "overlay = mark_boundaries(rgb, labels, color=(1, 0, 0))\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(2, 3, figsize=(14, 8))\n",
        "\n",
        "ax[0,0].imshow(rgb);        ax[0,0].set_title(\"Original RGB\");        ax[0,0].axis(\"off\")\n",
        "ax[0,1].imshow(gray, cmap=\"gray\"); ax[0,1].set_title(\"Grayscale (terrain)\"); ax[0,1].axis(\"off\")\n",
        "ax[0,2].imshow(grad, cmap=\"gray\"); ax[0,2].set_title(\"Gradient (ridges)\");   ax[0,2].axis(\"off\")\n",
        "\n",
        "ax[1,0].imshow(mask, cmap=\"gray\"); ax[1,0].set_title(\"Mask (where to segment)\"); ax[1,0].axis(\"off\")\n",
        "ax[1,1].imshow(dist, cmap=\"gray\"); ax[1,1].set_title(\"Distance transform (basins)\"); ax[1,1].axis(\"off\")\n",
        "ax[1,2].imshow(overlay);           ax[1,2].set_title(\"Watershed boundaries\"); ax[1,2].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Otsu threshold (for mask): {t:.3f}\")\n",
        "print(f\"Number of markers (seeds): {markers.max()}\")\n",
        "print(f\"Number of watershed regions: {labels.max()}\")\n"
      ],
      "metadata": {
        "id": "genhDIF_2L8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Watershed segmentation for all five images\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "\n",
        "from scipy import ndimage as ndi\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.feature import peak_local_max\n",
        "from skimage.filters import sobel, threshold_otsu\n",
        "from skimage.segmentation import watershed, mark_boundaries\n",
        "\n",
        "image_files = cropped_tifs[:5]\n",
        "\n",
        "fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(6, 12))\n",
        "plt.subplots_adjust(hspace=0.25, wspace=0.05)\n",
        "\n",
        "for row, path in enumerate(image_files):\n",
        "\n",
        "    # --- Load GeoTIFF (RGB) ---\n",
        "    with rasterio.open(path) as src:\n",
        "        rgb = src.read([1, 2, 3]).astype(np.float32).transpose(1, 2, 0)\n",
        "\n",
        "    # Percentile stretch -> [0,1] float for display/segmentation\n",
        "    p2, p98 = np.nanpercentile(rgb, (2, 98))\n",
        "    rgb_float = np.clip((rgb - p2) / (p98 - p2 + 1e-6), 0, 1)\n",
        "\n",
        "    # --- Watershed pipeline (like your snippet) ---\n",
        "    gray = rgb2gray(rgb_float)\n",
        "\n",
        "    gradient = sobel(gray)\n",
        "    otsu_t = threshold_otsu(gray)\n",
        "\n",
        "    mask = gray > otsu_t\n",
        "    distance = ndi.distance_transform_edt(mask)\n",
        "\n",
        "    # local maxima as markers\n",
        "    marker_coords = peak_local_max(distance, min_distance=15, labels=mask)\n",
        "\n",
        "    markers = np.zeros_like(gray, dtype=np.int32)\n",
        "    if len(marker_coords) > 0:\n",
        "        markers[tuple(marker_coords.T)] = np.arange(1, len(marker_coords) + 1)\n",
        "    else:\n",
        "        h, w = gray.shape\n",
        "        markers[h // 2, w // 2] = 1\n",
        "\n",
        "    markers, _ = ndi.label(markers > 0)\n",
        "\n",
        "    ws_labels = watershed(gradient, markers, mask=mask)\n",
        "\n",
        "    # boundaries overlay (red)\n",
        "    overlay = mark_boundaries(rgb_float, ws_labels, color=(1, 0, 0))\n",
        "\n",
        "    # Label\n",
        "    label = path.stem.replace(\"_rgb_cropped\", \"\").replace(\"_\", \" \").title()\n",
        "\n",
        "    # --- Plot original ---\n",
        "    axL = axes[row, 0]\n",
        "    axL.imshow(rgb_float)\n",
        "    axL.set_title(f\"{label}\", fontsize=12)\n",
        "    axL.axis(\"off\")\n",
        "\n",
        "    # --- Plot watershed overlay ---\n",
        "    axR = axes[row, 1]\n",
        "    axR.imshow(overlay)\n",
        "    axR.set_title(f\"Watershed\", fontsize=12)\n",
        "    axR.axis(\"off\")\n",
        "\n",
        "fig.suptitle(\"Landsat RGB (Left) vs Watershed Segmentation (Right)\", fontsize=16)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8YkfyNYrllKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sMexH1fx19_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Felzenszwalb graph segmentation\n",
        "\n",
        "Graph driven region merging via local intensity differences.\n",
        "\n",
        "This segmentation approach:\n",
        "- Builds a graph where each pixel is a node\n",
        "- Connects neighboring pixels with weighted edges\n",
        "- Sorts edges by weight (difference)\n",
        "- Merges regions if the boundary evidence is weak\n"
      ],
      "metadata": {
        "id": "J9FCI06LmPIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key parameters:\n",
        "- `scale`: larger gives larger segments.\n",
        "- `min_size`: removes tiny noisy segments."
      ],
      "metadata": {
        "id": "D3lbj4f7495I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Key papers:\n",
        "- Felzenszwalb, P. F., & Huttenlocher, D. P. (2004). *Efficient Graph-Based Image Segmentation*. IJCV, 59(2), 167-181.\n",
        "- Shi, J., & Malik, J. (2000). *Normalized Cuts and Image Segmentation*. IEEE TPAMI, 22(8), 888-905."
      ],
      "metadata": {
        "id": "7TL0TUyGmPIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Felzenszwalb graph-based segmentation\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from skimage.segmentation import felzenszwalb, mark_boundaries\n",
        "\n",
        "# Pick one image\n",
        "path = \"data_landsat/cropped/new_orleans_la_rgb_cropped.tif\"\n",
        "\n",
        "# Load RGB\n",
        "with rasterio.open(path) as src:\n",
        "    rgb = src.read([1, 2, 3]).astype(np.float32).transpose(1, 2, 0)\n",
        "\n",
        "# Normalize to [0,1] for segmentation + display\n",
        "p2, p98 = np.nanpercentile(rgb, (2, 98))\n",
        "rgb = np.clip((rgb - p2) / (p98 - p2 + 1e-6), 0, 1)\n",
        "\n",
        "# Felzenszwalb graph-based segmentation\n",
        "labels = felzenszwalb(rgb, scale=175, sigma=0.8, min_size=80)\n",
        "\n",
        "# Overlay boundaries\n",
        "overlay = mark_boundaries(rgb, labels, color=(0, 1, 1))\n",
        "\n",
        "# Show before/after using your helper\n",
        "show_pair(rgb, overlay, \"Felzenszwalb (boundaries)\")\n"
      ],
      "metadata": {
        "id": "jY3KBzf84dd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can visualize the gradient strength between pixels as follows.\n",
        "\n",
        "Bright pixels show a strong edge, indicating a likely boundary.\n",
        "\n",
        "Whereas, dark pixels show a weak edge, suggesting a likely merge region."
      ],
      "metadata": {
        "id": "_XcYLmiL5Y6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Visualize gradient (edge) strength\n",
        "from skimage.filters import sobel\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "grad = sobel(rgb.mean(axis=2))\n",
        "\n",
        "plt.imshow(grad, cmap=\"gray\")\n",
        "plt.title(\"Gradient (edge strength)\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TyUD5IIp5PrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Felzenszwalb applies Gaussian smoothing internally to control noise, as illustrated below.  "
      ],
      "metadata": {
        "id": "R-wsqBTK5wWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Applying Gaussian smoothing to reduce pixel noise\n",
        "from skimage.filters import gaussian\n",
        "\n",
        "smoothed = gaussian(rgb, sigma=0.8)\n",
        "\n",
        "show_pair(rgb, smoothed, \"Gaussian smoothing (sigma=0.8)\")"
      ],
      "metadata": {
        "id": "-XlW_0b65sUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we can view the pixel map."
      ],
      "metadata": {
        "id": "ee6iWc5Z6Dif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Felzenszwalb pixel map for New Orleans\n",
        "plt.imshow(labels, cmap=\"tab20\")\n",
        "plt.title(\"Felzenszwalb Label Map\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_63QzCRP6BWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we can replace each region with its mean color (indicating segments are coherent regions). The algorithm simplifies the image.\n"
      ],
      "metadata": {
        "id": "lCCz2e3J6W_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Felzenszwalb segment mean reconstruction\n",
        "recon = np.zeros_like(rgb)\n",
        "\n",
        "for lab in np.unique(labels):\n",
        "    mask = labels == lab\n",
        "    recon[mask] = rgb[mask].mean(axis=0)\n",
        "\n",
        "show_pair(rgb, recon, \"Region Mean Reconstruction\")\n"
      ],
      "metadata": {
        "id": "eEYd_zei6SGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can manipulate the scale variable to see how aggressively regions merge."
      ],
      "metadata": {
        "id": "B5U0Rhcs6pOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Varying the Felzenszwalb scale parameter\n",
        "labels_small = felzenszwalb(rgb, scale=50, sigma=0.8, min_size=80)\n",
        "labels_large = felzenszwalb(rgb, scale=300, sigma=0.8, min_size=80)\n",
        "\n",
        "overlay_small = mark_boundaries(rgb, labels_small)\n",
        "overlay_large = mark_boundaries(rgb, labels_large)\n",
        "\n",
        "show_pair(overlay_small, overlay_large,\n",
        "          \"Small scale (left) vs Large scale (right)\")\n"
      ],
      "metadata": {
        "id": "0WkP9IeG6U2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Felzenszwalb graph-based segmentation for all five images\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "\n",
        "from skimage.segmentation import felzenszwalb, mark_boundaries\n",
        "\n",
        "image_files = cropped_tifs[:5]\n",
        "\n",
        "fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(6, 12))\n",
        "plt.subplots_adjust(hspace=0.25, wspace=0.05)\n",
        "\n",
        "for row, path in enumerate(image_files):\n",
        "\n",
        "    # Load GeoTIFF (RGB)\n",
        "    with rasterio.open(path) as src:\n",
        "        rgb = src.read([1, 2, 3]).astype(np.float32).transpose(1, 2, 0)\n",
        "\n",
        "    # Percentile stretch -> [0,1] float for display/segmentation\n",
        "    p2, p98 = np.nanpercentile(rgb, (2, 98))\n",
        "    rgb_float = np.clip((rgb - p2) / (p98 - p2 + 1e-6), 0, 1)\n",
        "\n",
        "    # Felzenszwalb segmentation\n",
        "    felz_labels = felzenszwalb(\n",
        "        rgb_float,\n",
        "        scale=175,     # larger => larger segments\n",
        "        sigma=0.8,     # smoothing\n",
        "        min_size=80    # minimum segment size\n",
        "    )\n",
        "\n",
        "    # Boundary overlay (cyan)\n",
        "    overlay = mark_boundaries(rgb_float, felz_labels, color=(0, 1, 1))\n",
        "\n",
        "    # Label\n",
        "    label = path.stem.replace(\"_rgb_cropped\", \"\").replace(\"_\", \" \").title()\n",
        "\n",
        "    # Plot original\n",
        "    axL = axes[row, 0]\n",
        "    axL.imshow(rgb_float)\n",
        "    axL.set_title(f\"{label}\", fontsize=12)\n",
        "    axL.axis(\"off\")\n",
        "\n",
        "    # Plot Felzenszwalb overlay\n",
        "    axR = axes[row, 1]\n",
        "    axR.imshow(overlay)\n",
        "    axR.set_title(f\"Felzenszwalb\", fontsize=12)\n",
        "    axR.axis(\"off\")\n",
        "\n",
        "fig.suptitle(\"Landsat RGB (Left) vs Felzenszwalb Graph Segmentation (Right)\", fontsize=16)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "IpLIlVCXmm6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Putting all segmentation techniques together for inspection\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "\n",
        "from scipy import ndimage as ndi\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.filters import threshold_otsu, threshold_multiotsu, sobel\n",
        "from skimage.feature import peak_local_max\n",
        "from skimage.segmentation import slic, felzenszwalb, watershed, mark_boundaries\n",
        "\n",
        "def stretch01(rgb):\n",
        "    \"\"\"Percentile stretch to [0,1] float (consistent across methods).\"\"\"\n",
        "    p2, p98 = np.nanpercentile(rgb, (2, 98))\n",
        "    return np.clip((rgb - p2) / (p98 - p2 + 1e-6), 0, 1)\n",
        "\n",
        "def kmeans_quantize_rgb(rgb01, k=5, seed=42):\n",
        "    \"\"\"\n",
        "    K-means color quantization using scikit-learn (short + standard).\n",
        "    Input: rgb01 float in [0,1], shape (H,W,3)\n",
        "    Output: rgb01 float in [0,1], each pixel replaced by its centroid color\n",
        "    \"\"\"\n",
        "    h, w, _ = rgb01.shape\n",
        "    X = (rgb01.reshape(-1, 3) * 255).astype(np.float32)  # work in 0..255 space\n",
        "\n",
        "    km = KMeans(n_clusters=k, random_state=seed, n_init=10)\n",
        "    labels = km.fit_predict(X)\n",
        "\n",
        "    out = km.cluster_centers_[labels].reshape(h, w, 3) / 255.0\n",
        "    return np.clip(out, 0, 1)\n",
        "\n",
        "ordered_methods = [\n",
        "    \"otsu_thresholding\",\n",
        "    \"multi_otsu_3class\",\n",
        "    \"kmeans_rgb\",\n",
        "    \"slic_superpixels\",\n",
        "    \"watershed\",\n",
        "    \"felzenszwalb\",\n",
        "]\n",
        "\n",
        "nrows = len(cropped_tifs)\n",
        "ncols = 1 + len(ordered_methods)\n",
        "\n",
        "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(4 * ncols, 4 * nrows))\n",
        "if nrows == 1:\n",
        "    axes = axes[None, :]  # keep 2D indexing\n",
        "\n",
        "for r, path in enumerate(cropped_tifs):\n",
        "\n",
        "    with rasterio.open(path) as src: # Load RGB\n",
        "        rgb = src.read([1, 2, 3]).astype(np.float32).transpose(1, 2, 0)\n",
        "\n",
        "    rgb01 = stretch01(rgb)\n",
        "    gray = rgb2gray(rgb01)\n",
        "\n",
        "    location_label = path.stem.replace(\"_rgb_cropped\", \"\").replace(\"_\", \" \").title()\n",
        "\n",
        "    # Add original\n",
        "    axes[r, 0].imshow(rgb01)\n",
        "    axes[r, 0].set_title(f\"{location_label}\\nOriginal\", fontsize=11)\n",
        "    axes[r, 0].axis(\"off\")\n",
        "\n",
        "    # 1) Add Otsu (binary -> dim background)\n",
        "    t = threshold_otsu(gray)\n",
        "    mask = gray > t\n",
        "    otsu_vis = rgb01.copy()\n",
        "    otsu_vis[~mask] *= 0.25\n",
        "\n",
        "    # 2) Add Multi-Otsu (3 classes -> simple class colors)\n",
        "    t1, t2 = threshold_multiotsu(gray, classes=3)\n",
        "    seg3 = np.digitize(gray, bins=[t1, t2]).astype(np.uint8)\n",
        "    multi_vis = (rgb01 * 0.35).copy()\n",
        "    multi_vis[seg3 == 0] = [0.10, 0.20, 0.80]  # blue\n",
        "    multi_vis[seg3 == 1] = [0.20, 0.80, 0.20]  # green\n",
        "    multi_vis[seg3 == 2] = [0.90, 0.20, 0.20]  # red\n",
        "\n",
        "    # 3) Add K-means RGB\n",
        "    kmeans_vis = kmeans_quantize_rgb(rgb01, k=5, seed=42)\n",
        "\n",
        "    # 4) Add SLIC superpixels (boundaries)\n",
        "    slic_labels = slic(rgb01, n_segments=250, compactness=12.0, sigma=1.0, start_label=1)\n",
        "    slic_vis = mark_boundaries(rgb01, slic_labels, color=(1, 1, 0))  # yellow\n",
        "\n",
        "    # 5) Add Watershed (mask->distance->markers->watershed)\n",
        "    ws_mask = gray > threshold_otsu(gray)\n",
        "    dist = ndi.distance_transform_edt(ws_mask)\n",
        "    coords = peak_local_max(dist, min_distance=15, labels=ws_mask)\n",
        "\n",
        "    markers = np.zeros_like(gray, dtype=np.int32)\n",
        "    markers = ndi.label(markers > 0)[0]\n",
        "\n",
        "    ws_labels = watershed(sobel(gray), markers, mask=ws_mask)\n",
        "    ws_vis = mark_boundaries(rgb01, ws_labels, color=(1, 0, 0))  # red\n",
        "\n",
        "    # 6) Add Felzenszwalb (boundaries)\n",
        "    felz_labels = felzenszwalb(rgb01, scale=175, sigma=0.8, min_size=80)\n",
        "    felz_vis = mark_boundaries(rgb01, felz_labels, color=(0, 1, 1))  # cyan\n",
        "\n",
        "    results_row = {\n",
        "        \"otsu_thresholding\": otsu_vis,\n",
        "        \"multi_otsu_3class\": multi_vis,\n",
        "        \"kmeans_rgb\": kmeans_vis,\n",
        "        \"slic_superpixels\": slic_vis,\n",
        "        \"watershed\": ws_vis,\n",
        "        \"felzenszwalb\": felz_vis,\n",
        "    }\n",
        "\n",
        "    for c, method in enumerate(ordered_methods, start=1):\n",
        "        axes[r, c].imshow(results_row[method])\n",
        "        axes[r, c].set_title(method.replace(\"_\", \" \"), fontsize=11)\n",
        "        axes[r, c].axis(\"off\")\n",
        "\n",
        "fig.suptitle(\"Landsat: Original + 6 Segmentation Methods (Rows = Locations)\", fontsize=18, y=0.995)\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "D8z6z2t78E9y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}