{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUMjx+fdPjvUYrbv29ecor",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edwardoughton/satellite-image-analysis/blob/main/04_01_ggs416_26_02_16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üõ∞Ô∏è GGS416 Satellite Image Analysis Week 4 üõ∞Ô∏è\n",
        "\n",
        "This week we will cover:\n",
        "\n",
        " * Classical image segmentation approaches\n"
      ],
      "metadata": {
        "id": "5CfXtnDONcAX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning objectives\n",
        "\n",
        "By the end of this week, students will be able to:\n",
        "\n",
        "* Explain practical foundations of classical image segmentation methods.\n",
        "* Implement histogram-based segmentation using Otsu and Multi-Otsu thresholding.\n",
        "* Apply clustering-based segmentation using K-means in RGB feature space.\n",
        "* Generate superpixels using SLIC and interpret compactness effects.\n",
        "* Perform marker-controlled watershed segmentation.\n",
        "* Apply graph-based segmentation using the Felzenszwalb algorithm.\n",
        "* Compare segmentation outputs across heterogeneous landscapes (urban, agricultural, forest, coastal).\n",
        "* Analyze the influence of algorithm parameters on segmentation results.\n",
        "* Critically evaluate strengths and weaknesses of classical segmentation approaches for satellite imagery.\n",
        "\n"
      ],
      "metadata": {
        "id": "p5oPUH_XPZHQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Microsoft Copilot Pro\n",
        "\n",
        "Please sign up:\n",
        "\n",
        "https://docs.github.com/en/copilot/how-tos/manage-your-account/get-free-access-to-copilot-pro"
      ],
      "metadata": {
        "id": "B5XqnyzFqD2l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visual Studio Code\n",
        "\n",
        "Please install before next week:\n",
        "\n",
        "https://code.visualstudio.com/"
      ],
      "metadata": {
        "id": "9k03B2NiqPRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AI advice\n",
        "\n",
        "* Make sure you are using the newest models, where possible.\n",
        "* Free apps will have more outdated models.\n",
        "* Do use your educational email for free access to certain products."
      ],
      "metadata": {
        "id": "P7OkuPkdsWKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Setup and location presets\n",
        "!pip -q install pystac-client planetary-computer odc-stac rasterio requests\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from rasterio.transform import from_origin\n",
        "from rasterio.crs import CRS\n",
        "\n",
        "import pystac_client\n",
        "import planetary_computer\n",
        "import odc.stac\n",
        "from pystac.extensions.eo import EOExtension as eo"
      ],
      "metadata": {
        "id": "dBEXkHp_qB0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Location presets and search STAC\n",
        "!pip -q install pystac-client planetary-computer odc-stac rasterio requests\n",
        "\n",
        "STAC_API_URL = \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n",
        "COLLECTION = \"landsat-c2-l2\"\n",
        "\n",
        "# 5 locations (min_lon, min_lat, max_lon, max_lat) in EPSG:4326\n",
        "LOCATION_PRESETS = {\n",
        "    # Ames, Iowa ‚Äî agriculture patterns\n",
        "    \"agriculture_iowa_ames\": [\n",
        "        -93.77, 41.88,\n",
        "        -93.47, 42.18\n",
        "    ],\n",
        "\n",
        "    # Downtown Los Angeles ‚Äî dense urban core\n",
        "    \"urban_los_angeles_downtown\": [\n",
        "        -118.375, 33.90,\n",
        "        -118.075, 34.20\n",
        "    ],\n",
        "\n",
        "    # New Orleans ‚Äî Mississippi River bends + wetlands\n",
        "    \"coastal_louisiana_new_orleans\": [\n",
        "        -90.25, 29.80,\n",
        "        -89.95, 30.10\n",
        "    ],\n",
        "\n",
        "    # Phoenix ‚Äî desert‚Äìurban interface\n",
        "    \"desert_arizona_phoenix\": [\n",
        "        -112.25, 33.30,\n",
        "        -111.95, 33.60\n",
        "    ],\n",
        "\n",
        "    # Mount Jefferson area ‚Äî Cascades terrain + forest\n",
        "    \"forest_oregon_mt_jefferson\": [\n",
        "        -121.95, 44.50,\n",
        "        -121.65, 44.80\n",
        "    ],\n",
        "}\n",
        "\n",
        "time_of_interest = \"2024-05-01/2024-09-30\"\n",
        "cloud_limit = 10  # percent\n",
        "\n",
        "DATA_DIR = Path(\"data_landsat\")\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "catalog = pystac_client.Client.open(\n",
        "    STAC_API_URL,\n",
        "    modifier=planetary_computer.sign_inplace\n",
        ")\n",
        "\n",
        "print(catalog)"
      ],
      "metadata": {
        "id": "5qBBp8JaRFzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Cropping\n",
        "\n",
        "def save_rgb_geotiff_from_odc(data, out_path):\n",
        "    \"\"\"\n",
        "    Save RGB (red/green/blue) from an odc-stac xarray dataset to a GeoTIFF.\n",
        "    This keeps georeferencing so rasterio cropping works.\n",
        "    \"\"\"\n",
        "    # Build (bands, rows, cols) array for rasterio\n",
        "    rgb = data[[\"red\", \"green\", \"blue\"]].to_array().values  # shape (3, y, x)\n",
        "\n",
        "    # Get georeferencing from odc-stac dataset\n",
        "    transform = data.odc.geobox.transform\n",
        "    crs = data.odc.geobox.crs\n",
        "\n",
        "    profile = {\n",
        "        \"driver\": \"GTiff\",\n",
        "        \"height\": rgb.shape[1],\n",
        "        \"width\": rgb.shape[2],\n",
        "        \"count\": 3,\n",
        "        \"dtype\": rgb.dtype,\n",
        "        \"crs\": crs,\n",
        "        \"transform\": transform,\n",
        "    }\n",
        "\n",
        "    with rasterio.open(out_path, \"w\", **profile) as dst:\n",
        "        dst.write(rgb)\n",
        "\n",
        "    return out_path\n"
      ],
      "metadata": {
        "id": "I4XQSoe2qb8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Multi-image downloading and cropping\n",
        "downloaded_rgb_tifs = []\n",
        "\n",
        "for location_name, bbox in LOCATION_PRESETS.items():\n",
        "    print(f\"\\n--- {location_name} ---\")\n",
        "\n",
        "    search = catalog.search(\n",
        "        collections=[COLLECTION],\n",
        "        bbox=bbox,\n",
        "        datetime=time_of_interest,\n",
        "        query={\"eo:cloud_cover\": {\"lt\": cloud_limit}},\n",
        "    )\n",
        "\n",
        "    items = search.item_collection()\n",
        "    if len(items) == 0:\n",
        "        print(\"No scenes found.\")\n",
        "        continue\n",
        "\n",
        "    # Lecture 2: choose lowest cloud cover\n",
        "    selected_item = min(items, key=lambda item: eo.ext(item).cloud_cover)\n",
        "\n",
        "    print(\n",
        "        f\"Chosen: {selected_item.id}  |  Date: {selected_item.datetime.date()}  \"\n",
        "        f\"|  Cloud: {selected_item.properties['eo:cloud_cover']}%\"\n",
        "    )\n",
        "\n",
        "    # Lecture 2: load bands with odc-stac (we load a slightly larger area = your bbox)\n",
        "    bands = [\"red\", \"green\", \"blue\"]\n",
        "    data = odc.stac.stac_load([selected_item], bands=bands, bbox=bbox).isel(time=0)\n",
        "\n",
        "    out_tif = DATA_DIR / f\"{location_name}_rgb.tif\"\n",
        "    save_rgb_geotiff_from_odc(data, out_tif)\n",
        "\n",
        "    downloaded_rgb_tifs.append(out_tif)\n",
        "    print(\"Saved:\", out_tif)\n"
      ],
      "metadata": {
        "id": "piIMcE8Nqqqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Crop images (from Lecture 3)\n",
        "from rasterio.windows import from_bounds\n",
        "from rasterio.warp import transform_bounds\n",
        "\n",
        "CROPPED_DIR = DATA_DIR / \"cropped\"\n",
        "CROPPED_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "def crop_geotiff_to_bbox(in_path, out_path, bbox_wgs84):\n",
        "    \"\"\"\n",
        "    Crop a GeoTIFF to a lon/lat bbox using the Lecture 3 approach.\n",
        "    \"\"\"\n",
        "    with rasterio.open(in_path) as src:\n",
        "        # 1) Convert bbox from EPSG:4326 to the raster CRS (UTM for Landsat)\n",
        "        minlon, minlat, maxlon, maxlat = bbox_wgs84\n",
        "        minx, miny, maxx, maxy = transform_bounds(\n",
        "            \"EPSG:4326\", src.crs, minlon, minlat, maxlon, maxlat, densify_pts=21\n",
        "        )\n",
        "\n",
        "        # 2) Lecture 3: build a raster window from bounds\n",
        "        win = from_bounds(minx, miny, maxx, maxy, src.transform)\n",
        "\n",
        "        # 3) Read just that window\n",
        "        data = src.read(window=win)\n",
        "\n",
        "        # 4) Update metadata and write output (Lecture 3)\n",
        "        prof = src.profile\n",
        "        prof.update(\n",
        "            height=data.shape[1],\n",
        "            width=data.shape[2],\n",
        "            transform=rasterio.windows.transform(win, src.transform),\n",
        "        )\n",
        "\n",
        "        with rasterio.open(out_path, \"w\", **prof) as dst:\n",
        "            dst.write(data)\n",
        "\n",
        "    return out_path\n",
        "\n",
        "cropped_tifs = []\n",
        "\n",
        "for tif_path in downloaded_rgb_tifs:\n",
        "    location_name = tif_path.stem.replace(\"_rgb\", \"\")\n",
        "    bbox = LOCATION_PRESETS[location_name]\n",
        "\n",
        "    out_path = CROPPED_DIR / f\"{location_name}_rgb_cropped.tif\"\n",
        "    crop_geotiff_to_bbox(tif_path, out_path, bbox)\n",
        "\n",
        "    cropped_tifs.append(out_path)\n",
        "    print(\"Cropped:\", out_path.name)\n"
      ],
      "metadata": {
        "id": "zyINwlflVXWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Plot images (from Lecture 1)\n",
        "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, ax in enumerate(axes):\n",
        "    if i < len(cropped_tifs):\n",
        "        path = cropped_tifs[i]\n",
        "        label = path.stem.replace(\"_rgb_cropped\", \"\").replace(\"_\", \" \").title()\n",
        "\n",
        "        with rasterio.open(path) as src:\n",
        "            rgb = src.read([1, 2, 3]).astype(\"float32\")\n",
        "            rgb = rgb / (rgb.max() + 1e-6)          # normalize for display\n",
        "            rgb = rgb.transpose(1, 2, 0)            # (rows, cols, bands)\n",
        "\n",
        "        ax.imshow(rgb)\n",
        "        ax.set_title(label, fontsize=14)\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "        # Panel letter (A, B, C...)\n",
        "        ax.text(\n",
        "            0.02, 0.98, chr(ord(\"A\") + i),\n",
        "            transform=ax.transAxes,\n",
        "            va=\"top\", ha=\"left\",\n",
        "            fontsize=14,\n",
        "            bbox=dict(facecolor=\"white\", alpha=0.7, edgecolor=\"none\", pad=3)\n",
        "        )\n",
        "    else:\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "fig.suptitle(\"Landsat RGB ‚Äî Download + Crop\", fontsize=18)\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "IUJ-4QKnWW0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Otsu thresholding\n",
        "\n",
        "Segmentation approach:\n",
        "- Splits a grayscale image into foreground and background regions.\n",
        "- Automatically selects a threshold based on the image intensity histogram.\n",
        "\n",
        "Otsu selects the threshold that splits the image into two substantial groups, maximizing the distance between their average intensities.  \n",
        "\n",
        "Hence, we find the threshold that best separates foreground from background based on histogram structure.\n"
      ],
      "metadata": {
        "id": "XCSMjMmRaiwo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key parameters:\n",
        "- No manual threshold required.\n",
        "- Input quality depends on histogram separation.\n",
        "\n",
        "Key papers:\n",
        "- Otsu, N. (1979). *A Threshold Selection Method from Gray-Level Histograms*. IEEE Trans. SMC, 9(1), 62-66.\n",
        "- Sezgin, M., & Sankur, B. (2004). *Survey over image thresholding techniques and quantitative performance evaluation*. J. Electronic Imaging, 13(1), 146-165."
      ],
      "metadata": {
        "id": "EFwgIUJ2cVHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example:\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.filters import threshold_otsu\n",
        "\n",
        "image_files = cropped_tifs[:5]  # your cropped GeoTIFFs\n",
        "\n",
        "fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(12, 12))\n",
        "plt.subplots_adjust(hspace=0.25, wspace=0.05)\n",
        "\n",
        "for row, path in enumerate(image_files):\n",
        "\n",
        "    # --- Load GeoTIFF properly ---\n",
        "    with rasterio.open(path) as src:\n",
        "        rgb = src.read([1, 2, 3]).astype(\"float32\")  # (3, H, W)\n",
        "        rgb = rgb.transpose(1, 2, 0)                 # (H, W, 3)\n",
        "\n",
        "    # Normalize for display\n",
        "    rgb = rgb / (np.nanmax(rgb) + 1e-6)\n",
        "\n",
        "    # --- Otsu threshold ---\n",
        "    gray = rgb2gray(rgb)\n",
        "    t = threshold_otsu(gray)\n",
        "    mask = gray > t\n",
        "\n",
        "    # Dim background for visualization\n",
        "    otsu_vis = rgb.copy()\n",
        "    otsu_vis[~mask] *= 0.25\n",
        "\n",
        "    # Label\n",
        "    label = path.stem.replace(\"_rgb_cropped\", \"\").replace(\"_\", \" \").title()\n",
        "\n",
        "    # --- Plot original ---\n",
        "    axL = axes[row, 0]\n",
        "    axL.imshow(rgb)\n",
        "    axL.set_title(f\"{label} ‚Äî Original\", fontsize=12)\n",
        "    axL.axis(\"off\")\n",
        "\n",
        "    # --- Plot Otsu result ---\n",
        "    axR = axes[row, 1]\n",
        "    axR.imshow(otsu_vis)\n",
        "    axR.set_title(f\"{label} ‚Äî Otsu Threshold\", fontsize=12)\n",
        "    axR.axis(\"off\")\n",
        "\n",
        "fig.suptitle(\"Landsat RGB (Left) vs Otsu Segmentation (Right)\", fontsize=16)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hWRmwRpqcQUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Otsu thresholding (3 classes)\n",
        "\n",
        "Segmentation approach:\n",
        "- Extends Otsu to multiple classes.\n",
        "- Useful for coarse land-cover partitioning (dark/mid/bright regions).\n",
        "\n"
      ],
      "metadata": {
        "id": "l9Jshb1NeB5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key parameters:\n",
        "- `classes=3` (can also try 4 or 5).\n",
        "- Sensitive to histogram shape and contrast.\n",
        "\n",
        "Key papers:\n",
        "- Otsu, N. (1979). *A Threshold Selection Method from Gray-Level Histograms*. IEEE Trans. SMC, 9(1), 62-66.\n",
        "- Liao, P.-S., Chen, T.-S., & Chung, P.-C. (2001). *A fast algorithm for multilevel thresholding*. JISE, 17(5), 713-727.\n",
        "\n"
      ],
      "metadata": {
        "id": "kk6OfE0ueB5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example:\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.filters import threshold_multiotsu\n",
        "\n",
        "image_files = cropped_tifs[:5]  # your cropped GeoTIFFs\n",
        "\n",
        "fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(12, 12))\n",
        "plt.subplots_adjust(hspace=0.25, wspace=0.05)\n",
        "\n",
        "for row, path in enumerate(image_files):\n",
        "\n",
        "    # --- Load GeoTIFF properly ---\n",
        "    with rasterio.open(path) as src:\n",
        "        rgb = src.read([1, 2, 3]).astype(\"float32\")  # (3, H, W)\n",
        "        rgb = rgb.transpose(1, 2, 0)                 # (H, W, 3)\n",
        "\n",
        "    # Normalize for display\n",
        "    rgb = rgb / (np.nanmax(rgb) + 1e-6)\n",
        "\n",
        "    # --- Multi-Otsu threshold (3 classes) ---\n",
        "    gray = rgb2gray(rgb)\n",
        "\n",
        "    # thresholds will have length classes-1 = 2\n",
        "    t1, t2 = threshold_multiotsu(gray, classes=3)\n",
        "\n",
        "    # Convert grayscale into class labels: 0,1,2\n",
        "    seg = np.digitize(gray, bins=[t1, t2])\n",
        "\n",
        "    # --- Visualization: overlay the 3-class segmentation on the RGB ---\n",
        "    # Start from a dimmed version of the original\n",
        "    vis = (rgb * 0.35).copy()\n",
        "\n",
        "    # Colorize each class (no need for fancy colormaps; explicit & teachable)\n",
        "    # class 0 = dark pixels\n",
        "    vis[seg == 0] = [0.10, 0.20, 0.80]  # blue\n",
        "    # class 1 = mid pixels\n",
        "    vis[seg == 1] = [0.20, 0.80, 0.20]  # green\n",
        "    # class 2 = bright pixels\n",
        "    vis[seg == 2] = [0.90, 0.20, 0.20]  # red\n",
        "\n",
        "    # Label\n",
        "    label = path.stem.replace(\"_rgb_cropped\", \"\").replace(\"_\", \" \").title()\n",
        "\n",
        "    # --- Plot original ---\n",
        "    axL = axes[row, 0]\n",
        "    axL.imshow(rgb)\n",
        "    axL.set_title(f\"{label} ‚Äî Original\", fontsize=12)\n",
        "    axL.axis(\"off\")\n",
        "\n",
        "    # --- Plot Multi-Otsu result ---\n",
        "    axR = axes[row, 1]\n",
        "    axR.imshow(vis)\n",
        "    axR.set_title(f\"{label} ‚Äî Multi-Otsu (3 classes)\", fontsize=12)\n",
        "    axR.axis(\"off\")\n",
        "\n",
        "    # Optional: show thresholds in the console\n",
        "    print(f\"{label}: t1={t1:.3f}, t2={t2:.3f}\")\n",
        "\n",
        "fig.suptitle(\"Landsat RGB (Left) vs Multi-Otsu 3-Class Segmentation (Right)\", fontsize=16)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "DU3_iaHUfDPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example:\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.filters import threshold_multiotsu\n",
        "\n",
        "def show_new_orleans_multi_otsu(cropped_tifs):\n",
        "\n",
        "    # Find the New Orleans file\n",
        "    path = [p for p in cropped_tifs if \"new_orleans\" in p.stem.lower()][0]\n",
        "\n",
        "    # Load GeoTIFF\n",
        "    with rasterio.open(path) as src:\n",
        "        rgb = src.read([1, 2, 3]).astype(\"float32\")\n",
        "        rgb = rgb.transpose(1, 2, 0)\n",
        "\n",
        "    # Normalize\n",
        "    rgb = rgb / (np.nanmax(rgb) + 1e-6)\n",
        "\n",
        "    # Multi-Otsu (3 classes)\n",
        "    gray = rgb2gray(rgb)\n",
        "    thresholds = threshold_multiotsu(gray, classes=3)\n",
        "    seg = np.digitize(gray, bins=thresholds)\n",
        "\n",
        "    # Plot full-size\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(seg, cmap=\"viridis\")\n",
        "    plt.title(\"New Orleans ‚Äî Multi-Otsu (3 Classes)\", fontsize=16)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Thresholds: {thresholds}\")\n",
        "\n",
        "show_new_orleans_multi_otsu(cropped_tifs)\n"
      ],
      "metadata": {
        "id": "p5z6l2fQf3HB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-means (RGB clustering)\n",
        "\n",
        "Segmentation approach:\n",
        "- Clusters pixels in color space.\n",
        "- Each pixel is assigned to nearest color centroid.\n",
        "\n",
        "So, K-means segmentation groups pixels based on similarity in color space.\n",
        "\n",
        "For RGB images:\n",
        "- Each pixel is treated as a 3D vector $\n",
        "  x_i = [R_i, G_i, B_i]\n",
        "  $\n",
        "- Hence, pixels are clustered in this 3D space.\n",
        "- Each pixel is assigned to the nearest cluster centroid.\n",
        "\n",
        "Unlike Otsu (which uses intensity only), K-means operates in multivariate feature space."
      ],
      "metadata": {
        "id": "vKmsB_nIgQyX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key parameters:\n",
        "- `k`: number of clusters.\n",
        "- Iterations and initialization affect stability.\n",
        "\n",
        "\n",
        "Key papers:\n",
        "- MacQueen, J. (1967). *Some Methods for classification and Analysis of Multivariate Observations*. Proc. 5th Berkeley Symposium.\n",
        "- Lloyd, S. (1982). *Least squares quantization in PCM*. IEEE Trans. Information Theory, 28(2), 129-137."
      ],
      "metadata": {
        "id": "9XqC3gQvgQyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: K-means RGB segmentation\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "\n",
        "def kmeans_segment_rgb_uint8(rgb_uint8, k=5, iterations=18, seed=42):\n",
        "    \"\"\"\n",
        "    Very simple K-means on RGB pixels.\n",
        "    Input/Output: uint8 image in [0..255], shape (H,W,3)\n",
        "    Output: uint8 image where each pixel is replaced by its cluster centroid color.\n",
        "    \"\"\"\n",
        "    h, w, _ = rgb_uint8.shape\n",
        "    X = rgb_uint8.reshape(-1, 3).astype(np.float32)\n",
        "\n",
        "    rng = np.random.default_rng(seed)\n",
        "    centers = X[rng.choice(X.shape[0], size=k, replace=False)]\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        # Assign to nearest centroid\n",
        "        d2 = np.sum((X[:, None, :] - centers[None, :, :]) ** 2, axis=2)\n",
        "        labels = np.argmin(d2, axis=1)\n",
        "\n",
        "        # Update centroids\n",
        "        new_centers = centers.copy()\n",
        "        for j in range(k):\n",
        "            pts = X[labels == j]\n",
        "            if pts.size:\n",
        "                new_centers[j] = pts.mean(axis=0)\n",
        "\n",
        "        # Stop if stable\n",
        "        if np.allclose(new_centers, centers, atol=0.5):\n",
        "            centers = new_centers\n",
        "            break\n",
        "        centers = new_centers\n",
        "\n",
        "    out = centers[labels].reshape(h, w, 3)\n",
        "    return np.clip(out, 0, 255).astype(np.uint8)\n",
        "\n",
        "\n",
        "# ---- Apply to your 5 cropped GeoTIFFs and plot before/after ----\n",
        "image_files = cropped_tifs[:5]\n",
        "\n",
        "fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(12, 20))\n",
        "plt.subplots_adjust(hspace=0.25, wspace=0.05)\n",
        "\n",
        "k = 5\n",
        "\n",
        "for row, path in enumerate(image_files):\n",
        "\n",
        "    # Read GeoTIFF (bands, H, W) -> (H, W, 3)\n",
        "    with rasterio.open(path) as src:\n",
        "        rgb = src.read([1, 2, 3]).astype(np.float32).transpose(1, 2, 0)\n",
        "\n",
        "    # Convert to uint8 for a visible effect\n",
        "    # (percentile stretch tends to look better than max-normalization)\n",
        "    p2, p98 = np.nanpercentile(rgb, (2, 98))\n",
        "    rgb01 = np.clip((rgb - p2) / (p98 - p2 + 1e-6), 0, 1)\n",
        "    rgb8  = (rgb01 * 255).astype(np.uint8)\n",
        "\n",
        "    # ‚Äúresults[...] = ...‚Äù style\n",
        "    kmeans_rgb = kmeans_segment_rgb_uint8(rgb8, k=k, iterations=18)\n",
        "\n",
        "    label = path.stem.replace(\"_rgb_cropped\", \"\").replace(\"_\", \" \").title()\n",
        "\n",
        "    # Left: original\n",
        "    axL = axes[row, 0]\n",
        "    axL.imshow(rgb8)\n",
        "    axL.set_title(f\"{label} ‚Äî Original\", fontsize=12)\n",
        "    axL.axis(\"off\")\n",
        "\n",
        "    # Right: k-means quantized\n",
        "    axR = axes[row, 1]\n",
        "    axR.imshow(kmeans_rgb)\n",
        "    axR.set_title(f\"{label} ‚Äî K-means (k={k})\", fontsize=12)\n",
        "    axR.axis(\"off\")\n",
        "\n",
        "fig.suptitle(\"Landsat RGB (Left) vs K-means RGB Clustering (Right)\", fontsize=16)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tnUYDRgmiiiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Single-location K-means\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "\n",
        "def kmeans_segment_rgb_uint8(rgb_uint8, k=5, iterations=18, seed=42):\n",
        "    h, w, _ = rgb_uint8.shape\n",
        "    X = rgb_uint8.reshape(-1, 3).astype(np.float32)\n",
        "\n",
        "    rng = np.random.default_rng(seed)\n",
        "    centers = X[rng.choice(X.shape[0], size=k, replace=False)]\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        d2 = np.sum((X[:, None, :] - centers[None, :, :]) ** 2, axis=2)\n",
        "        labels = np.argmin(d2, axis=1)\n",
        "\n",
        "        new_centers = centers.copy()\n",
        "        for j in range(k):\n",
        "            pts = X[labels == j]\n",
        "            if pts.size:\n",
        "                new_centers[j] = pts.mean(axis=0)\n",
        "\n",
        "        if np.allclose(new_centers, centers, atol=0.5):\n",
        "            centers = new_centers\n",
        "            break\n",
        "        centers = new_centers\n",
        "\n",
        "    out = centers[labels].reshape(h, w, 3)\n",
        "    return np.clip(out, 0, 255).astype(np.uint8)\n",
        "\n",
        "\n",
        "def show_la_kmeans(cropped_tifs, k=5, iterations=18, seed=42):\n",
        "    # Find the LA file (works with your naming: \"urban_los_angeles_downtown_...\")\n",
        "    matches = [p for p in cropped_tifs if \"los_angeles\" in p.stem.lower()]\n",
        "    if not matches:\n",
        "        raise ValueError(\"Could not find a Los Angeles file in cropped_tifs (look for 'los_angeles' in filename).\")\n",
        "    path = matches[0]\n",
        "\n",
        "    # Load GeoTIFF RGB\n",
        "    with rasterio.open(path) as src:\n",
        "        rgb = src.read([1, 2, 3]).astype(np.float32).transpose(1, 2, 0)\n",
        "\n",
        "    # Percentile stretch -> uint8 for nicer display and clearer k-means effect\n",
        "    p2, p98 = np.nanpercentile(rgb, (2, 98))\n",
        "    rgb01 = np.clip((rgb - p2) / (p98 - p2 + 1e-6), 0, 1)\n",
        "    rgb8 = (rgb01 * 255).astype(np.uint8)\n",
        "\n",
        "    # K-means \"after\"\n",
        "    kmeans_rgb = kmeans_segment_rgb_uint8(rgb8, k=k, iterations=iterations, seed=seed)\n",
        "\n",
        "    label = path.stem.replace(\"_rgb_cropped\", \"\").replace(\"_\", \" \").title()\n",
        "\n",
        "    # Full-size side-by-side\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "    axes[0].imshow(rgb8)\n",
        "    axes[0].set_title(f\"{label} ‚Äî Original\", fontsize=14)\n",
        "    axes[0].axis(\"off\")\n",
        "\n",
        "    axes[1].imshow(kmeans_rgb)\n",
        "    axes[1].set_title(f\"{label} ‚Äî K-means (k={k})\", fontsize=14)\n",
        "    axes[1].axis(\"off\")\n",
        "\n",
        "    fig.suptitle(\"Los Angeles: RGB vs K-means Color Clustering\", fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Run it:\n",
        "show_la_kmeans(cropped_tifs, k=5)\n"
      ],
      "metadata": {
        "id": "04LHqER3iuuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Linear Iterative Clustering (SLIC) Superpixels\n",
        "\n",
        "SLIC (Simple Linear Iterative Clustering) groups pixels using a combined color + spatial distance metric.\n",
        "\n",
        "Segmentation approach:\n",
        "- Groups nearby pixels into compact superpixels.\n",
        "- Balances color similarity and spatial proximity.\n"
      ],
      "metadata": {
        "id": "HU852ohajoua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key parameters:\n",
        "- `n_segments`: number of superpixels.\n",
        "- `compactness`: spatial regularity vs boundary adherence.\n",
        "\n",
        "\n",
        "Key papers:\n",
        "- Achanta, R., et al. (2012). *SLIC Superpixels Compared to State-of-the-art Superpixel Methods*. IEEE TPAMI, 34(11), 2274-2282.\n",
        "- Stutz, D., Hermans, A., & Leibe, B. (2018). *Superpixels: An Evaluation of the State-of-the-Art*. CVIU, 166, 1-27."
      ],
      "metadata": {
        "id": "Xl8YJgYSjoua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Superpixels (SLIC)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "\n",
        "from skimage.segmentation import slic, mark_boundaries\n",
        "\n",
        "image_files = cropped_tifs[:5]\n",
        "\n",
        "fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(12, 20))\n",
        "plt.subplots_adjust(hspace=0.25, wspace=0.05)\n",
        "\n",
        "for row, path in enumerate(image_files):\n",
        "\n",
        "    # --- Load GeoTIFF properly ---\n",
        "    with rasterio.open(path) as src:\n",
        "        rgb = src.read([1, 2, 3]).astype(np.float32).transpose(1, 2, 0)\n",
        "\n",
        "    # Percentile stretch -> [0,1] float (helps SLIC + display)\n",
        "    p2, p98 = np.nanpercentile(rgb, (2, 98))\n",
        "    rgb_float = np.clip((rgb - p2) / (p98 - p2 + 1e-6), 0, 1)\n",
        "\n",
        "    # --- SLIC superpixels ---\n",
        "    slic_labels = slic(\n",
        "        rgb_float,\n",
        "        n_segments=250,\n",
        "        compactness=12.0,\n",
        "        sigma=1.0,\n",
        "        start_label=1\n",
        "    )\n",
        "\n",
        "    # Draw boundaries on top of the image (yellow-ish boundary color)\n",
        "    boundary_overlay = mark_boundaries(rgb_float, slic_labels, color=(1, 1, 0))\n",
        "\n",
        "    # Label\n",
        "    label = path.stem.replace(\"_rgb_cropped\", \"\").replace(\"_\", \" \").title()\n",
        "\n",
        "    # --- Plot original ---\n",
        "    axL = axes[row, 0]\n",
        "    axL.imshow(rgb_float)\n",
        "    axL.set_title(f\"{label} ‚Äî Original\", fontsize=12)\n",
        "    axL.axis(\"off\")\n",
        "\n",
        "    # --- Plot superpixels overlay ---\n",
        "    axR = axes[row, 1]\n",
        "    axR.imshow(boundary_overlay)\n",
        "    axR.set_title(f\"{label} ‚Äî SLIC superpixels\", fontsize=12)\n",
        "    axR.axis(\"off\")\n",
        "\n",
        "fig.suptitle(\"Landsat RGB (Left) vs SLIC Superpixels (Right)\", fontsize=16)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aQx3dOsRkxoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Superpixels focusing on Phoenix, AZ\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "\n",
        "from skimage.segmentation import slic, mark_boundaries\n",
        "\n",
        "def show_phoenix_slic(cropped_tifs):\n",
        "\n",
        "    # Find the Phoenix file\n",
        "    matches = [p for p in cropped_tifs if \"phoenix\" in p.stem.lower()]\n",
        "    if not matches:\n",
        "        raise ValueError(\"Could not find a Phoenix file in cropped_tifs.\")\n",
        "    path = matches[0]\n",
        "\n",
        "    # --- Load GeoTIFF ---\n",
        "    with rasterio.open(path) as src:\n",
        "        rgb = src.read([1, 2, 3]).astype(np.float32).transpose(1, 2, 0)\n",
        "\n",
        "    # Percentile stretch for better contrast\n",
        "    p2, p98 = np.nanpercentile(rgb, (2, 98))\n",
        "    rgb_float = np.clip((rgb - p2) / (p98 - p2 + 1e-6), 0, 1)\n",
        "\n",
        "    # --- SLIC superpixels ---\n",
        "    slic_labels = slic(\n",
        "        rgb_float,\n",
        "        n_segments=300,\n",
        "        compactness=10.0,\n",
        "        sigma=1.0,\n",
        "        start_label=1\n",
        "    )\n",
        "\n",
        "    overlay = mark_boundaries(rgb_float, slic_labels, color=(1, 1, 0))\n",
        "\n",
        "    label = path.stem.replace(\"_rgb_cropped\", \"\").replace(\"_\", \" \").title()\n",
        "\n",
        "    # --- Plot side-by-side ---\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "    axes[0].imshow(rgb_float)\n",
        "    axes[0].set_title(f\"{label} ‚Äî Original\", fontsize=14)\n",
        "    axes[0].axis(\"off\")\n",
        "\n",
        "    axes[1].imshow(overlay)\n",
        "    axes[1].set_title(f\"{label} ‚Äî SLIC Superpixels\", fontsize=14)\n",
        "    axes[1].axis(\"off\")\n",
        "\n",
        "    fig.suptitle(\"Phoenix: RGB vs SLIC Superpixel Segmentation\", fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Run it\n",
        "show_phoenix_slic(cropped_tifs)\n"
      ],
      "metadata": {
        "id": "H2T02OfilEq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Watershed segmentation\n",
        "\n",
        "Segmentation approach:\n",
        "- Treats the gradient magnitude image as a topographic surface and performs region flooding from predefined markers.\n",
        "- Produces region boundaries from gradient basins.\n"
      ],
      "metadata": {
        "id": "6O5-vKoblTz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key parameters:\n",
        "- Marker strategy strongly affects output.\n",
        "- `min_distance` in peak detection controls seed density.\n",
        "\n",
        "\n",
        "Key papers:\n",
        "- Vincent, L., & Soille, P. (1991). *Watersheds in digital spaces: An efficient algorithm based on immersion simulations*. IEEE TPAMI, 13(6), 583-598.\n",
        "- Roerdink, J. B. T. M., & Meijster, A. (2000). *The Watershed Transform: Definitions, Algorithms and Parallelization Strategies*. Fundamenta Informaticae, 41, 187-228."
      ],
      "metadata": {
        "id": "7IE4vmv4lTz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Watershed segmentation\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "\n",
        "from scipy import ndimage as ndi\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.feature import peak_local_max\n",
        "from skimage.filters import sobel, threshold_otsu\n",
        "from skimage.segmentation import watershed, mark_boundaries\n",
        "\n",
        "image_files = cropped_tifs[:5]\n",
        "\n",
        "fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(12, 20))\n",
        "plt.subplots_adjust(hspace=0.25, wspace=0.05)\n",
        "\n",
        "for row, path in enumerate(image_files):\n",
        "\n",
        "    # --- Load GeoTIFF (RGB) ---\n",
        "    with rasterio.open(path) as src:\n",
        "        rgb = src.read([1, 2, 3]).astype(np.float32).transpose(1, 2, 0)\n",
        "\n",
        "    # Percentile stretch -> [0,1] float for display/segmentation\n",
        "    p2, p98 = np.nanpercentile(rgb, (2, 98))\n",
        "    rgb_float = np.clip((rgb - p2) / (p98 - p2 + 1e-6), 0, 1)\n",
        "\n",
        "    # --- Watershed pipeline (like your snippet) ---\n",
        "    gray = rgb2gray(rgb_float)\n",
        "\n",
        "    gradient = sobel(gray)\n",
        "    otsu_t = threshold_otsu(gray)\n",
        "\n",
        "    mask = gray > otsu_t\n",
        "    distance = ndi.distance_transform_edt(mask)\n",
        "\n",
        "    # local maxima as markers\n",
        "    marker_coords = peak_local_max(distance, min_distance=15, labels=mask)\n",
        "\n",
        "    markers = np.zeros_like(gray, dtype=np.int32)\n",
        "    if len(marker_coords) > 0:\n",
        "        markers[tuple(marker_coords.T)] = np.arange(1, len(marker_coords) + 1)\n",
        "    else:\n",
        "        h, w = gray.shape\n",
        "        markers[h // 2, w // 2] = 1\n",
        "\n",
        "    markers, _ = ndi.label(markers > 0)\n",
        "\n",
        "    ws_labels = watershed(gradient, markers, mask=mask)\n",
        "\n",
        "    # boundaries overlay (red)\n",
        "    overlay = mark_boundaries(rgb_float, ws_labels, color=(1, 0, 0))\n",
        "\n",
        "    # Label\n",
        "    label = path.stem.replace(\"_rgb_cropped\", \"\").replace(\"_\", \" \").title()\n",
        "\n",
        "    # --- Plot original ---\n",
        "    axL = axes[row, 0]\n",
        "    axL.imshow(rgb_float)\n",
        "    axL.set_title(f\"{label} ‚Äî Original\", fontsize=12)\n",
        "    axL.axis(\"off\")\n",
        "\n",
        "    # --- Plot watershed overlay ---\n",
        "    axR = axes[row, 1]\n",
        "    axR.imshow(overlay)\n",
        "    axR.set_title(f\"{label} ‚Äî Watershed\", fontsize=12)\n",
        "    axR.axis(\"off\")\n",
        "\n",
        "fig.suptitle(\"Landsat RGB (Left) vs Watershed Segmentation (Right)\", fontsize=16)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8YkfyNYrllKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example:\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "\n",
        "from scipy import ndimage as ndi\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.feature import peak_local_max\n",
        "from skimage.filters import sobel, threshold_otsu\n",
        "from skimage.segmentation import watershed, mark_boundaries\n",
        "\n",
        "\n",
        "def show_oregon_watershed(cropped_tifs):\n",
        "\n",
        "    # Find Oregon file\n",
        "    matches = [p for p in cropped_tifs if \"oregon\" in p.stem.lower()]\n",
        "    if not matches:\n",
        "        raise ValueError(\"Could not find an Oregon file in cropped_tifs.\")\n",
        "    path = matches[0]\n",
        "\n",
        "    # --- Load GeoTIFF ---\n",
        "    with rasterio.open(path) as src:\n",
        "        rgb = src.read([1, 2, 3]).astype(np.float32).transpose(1, 2, 0)\n",
        "\n",
        "    # Percentile stretch for better contrast\n",
        "    p2, p98 = np.nanpercentile(rgb, (2, 98))\n",
        "    rgb_float = np.clip((rgb - p2) / (p98 - p2 + 1e-6), 0, 1)\n",
        "\n",
        "    # --- Watershed segmentation ---\n",
        "    gray = rgb2gray(rgb_float)\n",
        "    gradient = sobel(gray)\n",
        "\n",
        "    otsu_t = threshold_otsu(gray)\n",
        "    mask = gray > otsu_t\n",
        "\n",
        "    distance = ndi.distance_transform_edt(mask)\n",
        "\n",
        "    marker_coords = peak_local_max(distance, min_distance=20, labels=mask)\n",
        "\n",
        "    markers = np.zeros_like(gray, dtype=np.int32)\n",
        "    if len(marker_coords) > 0:\n",
        "        markers[tuple(marker_coords.T)] = np.arange(1, len(marker_coords) + 1)\n",
        "    else:\n",
        "        h, w = gray.shape\n",
        "        markers[h // 2, w // 2] = 1\n",
        "\n",
        "    markers, _ = ndi.label(markers > 0)\n",
        "\n",
        "    ws_labels = watershed(gradient, markers, mask=mask)\n",
        "\n",
        "    overlay = mark_boundaries(rgb_float, ws_labels, color=(1, 0, 0))\n",
        "\n",
        "    label = path.stem.replace(\"_rgb_cropped\", \"\").replace(\"_\", \" \").title()\n",
        "\n",
        "    # --- Plot side-by-side ---\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "    axes[0].imshow(rgb_float)\n",
        "    axes[0].set_title(f\"{label} ‚Äî Original\", fontsize=14)\n",
        "    axes[0].axis(\"off\")\n",
        "\n",
        "    axes[1].imshow(overlay)\n",
        "    axes[1].set_title(f\"{label} ‚Äî Watershed Segmentation\", fontsize=14)\n",
        "    axes[1].axis(\"off\")\n",
        "\n",
        "    fig.suptitle(\"Oregon Cascades: RGB vs Watershed\", fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Run it\n",
        "show_oregon_watershed(cropped_tifs)\n"
      ],
      "metadata": {
        "id": "Se04g4VSl_5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Felzenszwalb graph segmentation\n",
        "\n",
        "Segmentation approach:\n",
        "- Builds a graph of pixels with weighted edges.\n",
        "- Merges regions based on internal consistency and boundary contrast.\n"
      ],
      "metadata": {
        "id": "J9FCI06LmPIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key parameters:\n",
        "- `scale`: larger gives larger segments.\n",
        "- `min_size`: removes tiny noisy segments.\n",
        "\n",
        "Key papers:\n",
        "- Felzenszwalb, P. F., & Huttenlocher, D. P. (2004). *Efficient Graph-Based Image Segmentation*. IJCV, 59(2), 167-181.\n",
        "- Shi, J., & Malik, J. (2000). *Normalized Cuts and Image Segmentation*. IEEE TPAMI, 22(8), 888-905."
      ],
      "metadata": {
        "id": "7TL0TUyGmPIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example:Felzenszwalb graph-based segmentation\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "\n",
        "from skimage.segmentation import felzenszwalb, mark_boundaries\n",
        "\n",
        "image_files = cropped_tifs[:5]\n",
        "\n",
        "fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(12, 20))\n",
        "plt.subplots_adjust(hspace=0.25, wspace=0.05)\n",
        "\n",
        "for row, path in enumerate(image_files):\n",
        "\n",
        "    # --- Load GeoTIFF (RGB) ---\n",
        "    with rasterio.open(path) as src:\n",
        "        rgb = src.read([1, 2, 3]).astype(np.float32).transpose(1, 2, 0)\n",
        "\n",
        "    # Percentile stretch -> [0,1] float for display/segmentation\n",
        "    p2, p98 = np.nanpercentile(rgb, (2, 98))\n",
        "    rgb_float = np.clip((rgb - p2) / (p98 - p2 + 1e-6), 0, 1)\n",
        "\n",
        "    # --- Felzenszwalb segmentation (like your snippet) ---\n",
        "    felz_labels = felzenszwalb(\n",
        "        rgb_float,\n",
        "        scale=175,     # larger => larger segments\n",
        "        sigma=0.8,     # smoothing\n",
        "        min_size=80    # minimum segment size\n",
        "    )\n",
        "\n",
        "    # Boundary overlay (cyan)\n",
        "    overlay = mark_boundaries(rgb_float, felz_labels, color=(0, 1, 1))\n",
        "\n",
        "    # Label\n",
        "    label = path.stem.replace(\"_rgb_cropped\", \"\").replace(\"_\", \" \").title()\n",
        "\n",
        "    # --- Plot original ---\n",
        "    axL = axes[row, 0]\n",
        "    axL.imshow(rgb_float)\n",
        "    axL.set_title(f\"{label} ‚Äî Original\", fontsize=12)\n",
        "    axL.axis(\"off\")\n",
        "\n",
        "    # --- Plot Felzenszwalb overlay ---\n",
        "    axR = axes[row, 1]\n",
        "    axR.imshow(overlay)\n",
        "    axR.set_title(f\"{label} ‚Äî Felzenszwalb\", fontsize=12)\n",
        "    axR.axis(\"off\")\n",
        "\n",
        "fig.suptitle(\"Landsat RGB (Left) vs Felzenszwalb Graph Segmentation (Right)\", fontsize=16)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "IpLIlVCXmm6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Single-location Felzenszwalb\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "\n",
        "from skimage.segmentation import felzenszwalb, mark_boundaries\n",
        "\n",
        "def show_iowa_felzenszwalb(cropped_tifs, scale=175, sigma=0.8, min_size=80):\n",
        "\n",
        "    # Find the Iowa file\n",
        "    matches = [p for p in cropped_tifs if \"iowa\" in p.stem.lower()]\n",
        "    if not matches:\n",
        "        raise ValueError(\"Could not find an Iowa file in cropped_tifs (look for 'iowa' in filename).\")\n",
        "    path = matches[0]\n",
        "\n",
        "    # --- Load GeoTIFF (RGB) ---\n",
        "    with rasterio.open(path) as src:\n",
        "        rgb = src.read([1, 2, 3]).astype(np.float32).transpose(1, 2, 0)\n",
        "\n",
        "    # Percentile stretch -> [0,1] float\n",
        "    p2, p98 = np.nanpercentile(rgb, (2, 98))\n",
        "    rgb_float = np.clip((rgb - p2) / (p98 - p2 + 1e-6), 0, 1)\n",
        "\n",
        "    # --- Felzenszwalb segmentation ---\n",
        "    felz_labels = felzenszwalb(rgb_float, scale=scale, sigma=sigma, min_size=min_size)\n",
        "    overlay = mark_boundaries(rgb_float, felz_labels, color=(0, 1, 1))  # cyan boundaries\n",
        "\n",
        "    label = path.stem.replace(\"_rgb_cropped\", \"\").replace(\"_\", \" \").title()\n",
        "\n",
        "    # --- Plot before/after ---\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "    axes[0].imshow(rgb_float)\n",
        "    axes[0].set_title(f\"{label} ‚Äî Original\", fontsize=14)\n",
        "    axes[0].axis(\"off\")\n",
        "\n",
        "    axes[1].imshow(overlay)\n",
        "    axes[1].set_title(f\"{label} ‚Äî Felzenszwalb\", fontsize=14)\n",
        "    axes[1].axis(\"off\")\n",
        "\n",
        "    fig.suptitle(\"Iowa: RGB vs Felzenszwalb Graph Segmentation\", fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Run it\n",
        "show_iowa_felzenszwalb(cropped_tifs)\n"
      ],
      "metadata": {
        "id": "IfAXXzOLmuvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Putting all our techniques together\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "\n",
        "from scipy import ndimage as ndi\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.filters import threshold_otsu, threshold_multiotsu, sobel\n",
        "from skimage.feature import peak_local_max\n",
        "from skimage.segmentation import slic, felzenszwalb, watershed, mark_boundaries\n",
        "\n",
        "# --- Simple helpers (kept short for teaching) ---\n",
        "def stretch01(rgb):\n",
        "    p2, p98 = np.nanpercentile(rgb, (2, 98))\n",
        "    return np.clip((rgb - p2) / (p98 - p2 + 1e-6), 0, 1)\n",
        "\n",
        "def kmeans_segment_rgb_uint8(rgb_uint8, k=5, iterations=18, seed=42):\n",
        "    h, w, _ = rgb_uint8.shape\n",
        "    X = rgb_uint8.reshape(-1, 3).astype(np.float32)\n",
        "    rng = np.random.default_rng(seed)\n",
        "    centers = X[rng.choice(X.shape[0], size=k, replace=False)]\n",
        "    for _ in range(iterations):\n",
        "        d2 = np.sum((X[:, None, :] - centers[None, :, :]) ** 2, axis=2)\n",
        "        labels = np.argmin(d2, axis=1)\n",
        "        new_centers = centers.copy()\n",
        "        for j in range(k):\n",
        "            pts = X[labels == j]\n",
        "            if pts.size:\n",
        "                new_centers[j] = pts.mean(axis=0)\n",
        "        if np.allclose(new_centers, centers, atol=0.5):\n",
        "            centers = new_centers\n",
        "            break\n",
        "        centers = new_centers\n",
        "    out = centers[labels].reshape(h, w, 3)\n",
        "    return np.clip(out, 0, 255).astype(np.uint8)\n",
        "\n",
        "# --- Methods (order matches your list) ---\n",
        "ordered_methods = [\n",
        "    \"otsu_thresholding\",\n",
        "    \"multi_otsu_3class\",\n",
        "    \"kmeans_rgb\",\n",
        "    \"slic_superpixels\",\n",
        "    \"watershed\",\n",
        "    \"felzenszwalb\",\n",
        "]\n",
        "\n",
        "# Choose the 5 images (assumes cropped_tifs already created)\n",
        "image_files = cropped_tifs[:5]\n",
        "\n",
        "nrows = len(image_files)\n",
        "ncols = 1 + len(ordered_methods)\n",
        "\n",
        "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(4 * ncols, 4 * nrows))\n",
        "if nrows == 1:\n",
        "    axes = axes[None, :]  # keep 2D indexing\n",
        "\n",
        "for r, path in enumerate(image_files):\n",
        "\n",
        "    # ---- Load + normalize RGB ----\n",
        "    with rasterio.open(path) as src:\n",
        "        rgb = src.read([1, 2, 3]).astype(np.float32).transpose(1, 2, 0)\n",
        "\n",
        "    rgb_float = stretch01(rgb)  # [0,1]\n",
        "    gray = rgb2gray(rgb_float)\n",
        "\n",
        "    # Row label\n",
        "    location_label = path.stem.replace(\"_rgb_cropped\", \"\").replace(\"_\", \" \").title()\n",
        "\n",
        "    # ---- Original ----\n",
        "    axes[r, 0].imshow(rgb_float)\n",
        "    axes[r, 0].set_title(f\"{location_label}\\nOriginal\", fontsize=11)\n",
        "    axes[r, 0].axis(\"off\")\n",
        "\n",
        "    # ---- 1) Otsu (binary) ----\n",
        "    t = threshold_otsu(gray)\n",
        "    mask = gray > t\n",
        "    otsu_vis = rgb_float.copy()\n",
        "    otsu_vis[~mask] *= 0.25\n",
        "\n",
        "    # ---- 2) Multi-Otsu (3 classes) ----\n",
        "    t1, t2 = threshold_multiotsu(gray, classes=3)\n",
        "    seg3 = np.digitize(gray, bins=[t1, t2])\n",
        "    multi_vis = (rgb_float * 0.35).copy()\n",
        "    multi_vis[seg3 == 0] = [0.10, 0.20, 0.80]  # blue\n",
        "    multi_vis[seg3 == 1] = [0.20, 0.80, 0.20]  # green\n",
        "    multi_vis[seg3 == 2] = [0.90, 0.20, 0.20]  # red\n",
        "\n",
        "    # ---- 3) K-means RGB (color quantization) ----\n",
        "    rgb8 = (rgb_float * 255).astype(np.uint8)\n",
        "    kmeans_vis = kmeans_segment_rgb_uint8(rgb8, k=5, iterations=18, seed=42) / 255.0\n",
        "\n",
        "    # ---- 4) SLIC superpixels ----\n",
        "    slic_labels = slic(rgb_float, n_segments=250, compactness=12.0, sigma=1.0, start_label=1)\n",
        "    slic_vis = mark_boundaries(rgb_float, slic_labels, color=(1, 1, 0))  # yellow edges\n",
        "\n",
        "    # ---- 5) Watershed ----\n",
        "    gradient = sobel(gray)\n",
        "    otsu_t = threshold_otsu(gray)\n",
        "    ws_mask = gray > otsu_t\n",
        "    distance = ndi.distance_transform_edt(ws_mask)\n",
        "\n",
        "    marker_coords = peak_local_max(distance, min_distance=15, labels=ws_mask)\n",
        "    markers = np.zeros_like(gray, dtype=np.int32)\n",
        "    if len(marker_coords) > 0:\n",
        "        markers[tuple(marker_coords.T)] = np.arange(1, len(marker_coords) + 1)\n",
        "    else:\n",
        "        h, w = gray.shape\n",
        "        markers[h // 2, w // 2] = 1\n",
        "    markers, _ = ndi.label(markers > 0)\n",
        "\n",
        "    ws_labels = watershed(gradient, markers, mask=ws_mask)\n",
        "    ws_vis = mark_boundaries(rgb_float, ws_labels, color=(1, 0, 0))  # red edges\n",
        "\n",
        "    # ---- 6) Felzenszwalb ----\n",
        "    felz_labels = felzenszwalb(rgb_float, scale=175, sigma=0.8, min_size=80)\n",
        "    felz_vis = mark_boundaries(rgb_float, felz_labels, color=(0, 1, 1))  # cyan edges\n",
        "\n",
        "    # Collect results in the same order as ordered_methods\n",
        "    results_row = {\n",
        "        \"otsu_thresholding\": otsu_vis,\n",
        "        \"multi_otsu_3class\": multi_vis,\n",
        "        \"kmeans_rgb\": kmeans_vis,\n",
        "        \"slic_superpixels\": slic_vis,\n",
        "        \"watershed\": ws_vis,\n",
        "        \"felzenszwalb\": felz_vis,\n",
        "    }\n",
        "\n",
        "    # ---- Plot each method ----\n",
        "    for c, method in enumerate(ordered_methods, start=1):\n",
        "        axes[r, c].imshow(results_row[method])\n",
        "        axes[r, c].set_title(method.replace(\"_\", \" \"), fontsize=11)\n",
        "        axes[r, c].axis(\"off\")\n",
        "\n",
        "fig.suptitle(\"Landsat: Original + 6 Segmentation Methods (Rows = Locations)\", fontsize=18, y=0.995)\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0nOfkXZ-ncil"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}